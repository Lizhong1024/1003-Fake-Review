{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab will introduce to:\n",
    "* Tokenization \n",
    "* Dataset and Dataloader in PyTorch\n",
    "* Bag-of-Words (BoW) models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by downloading 20-newsgroup text dataset:\n",
    "\n",
    "```http://scikit-learn.org/stable/datasets/index.html#the-20-newsgroups-text-dataset```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroup_train = fetch_20newsgroups(subset='train')\n",
    "newsgroup_test = fetch_20newsgroups(subset='test') # we will use it later\n",
    "print(type(newsgroup_train))\n",
    "print(type(newsgroup_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 10000\n",
      "Val dataset size is 1314\n",
      "Test dataset size is 7532\n"
     ]
    }
   ],
   "source": [
    "# Split train data into actual train and validation sets\n",
    "\n",
    "train_split = 10000\n",
    "train_data = newsgroup_train.data[:train_split]\n",
    "train_targets = newsgroup_train.target[:train_split]\n",
    "\n",
    "val_data = newsgroup_train.data[train_split:]\n",
    "val_targets = newsgroup_train.target[train_split:]\n",
    "\n",
    "test_data = newsgroup_test.data\n",
    "test_targets = newsgroup_test.target\n",
    "\n",
    "print (\"Train dataset size is {}\".format(len(train_data)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels are {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Numbers of target variables: 20\n"
     ]
    }
   ],
   "source": [
    "print (\"Unique labels are {}\".format((set(test_targets))))\n",
    "print (\"Numbers of target variables: {}\".format(len(set(test_targets))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(list(newsgroup_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: hades@coos.dartmouth.edu (Brian V. Hughes)\n",
      "Subject: Re: LCIII->PowerPC?\n",
      "Reply-To: hades@Dartmouth.Edu\n",
      "Organization: Dartmouth College, Hanover, NH\n",
      "Disclaimer: Personally, I really don't care who you think I speak for.\n",
      "Moderator: Rec.Arts.Comics.Info\n",
      "Lines: 10\n",
      "\n",
      "mirsky@hal.gnu.ai.mit.edu (David Joshua Mirsky) writes:\n",
      "\n",
      ">Hi. I own an LCIII and I recently heard an interesting rumor.\n",
      ">I heard that the LCIII has a built in slot for a PowerPC chip.\n",
      ">Is this true? I heard that the slot is not the same as the PDS\n",
      ">slot.  Is that true?\n",
      "\n",
      "    Don't believe the hype. There is no such thing as a PowerPC slot.\n",
      "\n",
      "-Hades\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random sample from train dataset\n",
    "import random\n",
    "print (train_data[random.randint(0, len(train_data) - 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing Dataset\n",
    "\n",
    "Before we trian the classifer, we have to tokenize the dataset. Tokenization is basically just chopping your sequence (in this case our document or sentences) into small consistuent units (we will choose words as our units), often times, throwing away some characters like puctuation marks or some special symbols. One could also consider doing transformations like mapping all characters to small letters as a part of tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to tokenize the dataset using [spacy.io](https://spacy.io/)\n",
    "\n",
    "Run (shown in the cell below):\n",
    "\n",
    "* ```pip install spacy``` <br>\n",
    "or if you want to you use conda\n",
    "* ```conda install -c conda-forge spacy```\n",
    "\n",
    "followed by\n",
    "* ```python -m spacy download en_core_web_sm```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'is', 'looking', 'at', 'buying', 'u.k.', 'startup', 'for', '1', 'billion']\n"
     ]
    }
   ],
   "source": [
    "# Let's write the tokenization function \n",
    "\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# lowercase and remove punctuation\n",
    "def tokenize(sent):\n",
    "  tokens = tokenizer(sent)\n",
    "  return [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "\n",
    "# Example\n",
    "tokens = tokenize(u'Apple is looking at buying U.K. startup for $1 billion.')\n",
    "print (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing val data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8db4f492a605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#val set tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Tokenizing val data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mval_data_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val_data_tokens.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8db4f492a605>\u001b[0m in \u001b[0;36mtokenize_dataset\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtoken_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mall_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6b01b9c9a9f8>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# lowercase and remove punctuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunctuations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This is the code cell that tokenizes train/val/test datasets\n",
    "# However it takes about 15-20 minutes to run it\n",
    "# For convinience we have provided the preprocessed datasets\n",
    "# Please see the next code cell\n",
    "# Don't run this cell, o.w. it will write over the files downloaded in the next cell\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    token_dataset = []\n",
    "    # we are keeping track of all tokens in dataset \n",
    "    # in order to create vocabulary later\n",
    "    all_tokens = []\n",
    "    \n",
    "    for sample in dataset:\n",
    "        tokens = tokenize(sample)\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "\n",
    "    return token_dataset, all_tokens\n",
    "\n",
    "#val set tokens\n",
    "print (\"Tokenizing val data\")\n",
    "val_data_tokens, _ = tokenize_dataset(val_data)\n",
    "pkl.dump(val_data_tokens, open(\"val_data_tokens.p\", \"wb\"))\n",
    "\n",
    "#test set tokens\n",
    "print (\"Tokenizing test data\")\n",
    "test_data_tokens, _ = tokenize_dataset(test_data)\n",
    "pkl.dump(test_data_tokens, open(\"test_data_tokens.p\", \"wb\"))\n",
    "\n",
    "#train set tokens\n",
    "print (\"Tokenizing train data\")\n",
    "train_data_tokens, all_train_tokens = tokenize_dataset(train_data)\n",
    "pkl.dump(train_data_tokens, open(\"train_data_tokens.p\", \"wb\"))\n",
    "pkl.dump(all_train_tokens, open(\"all_train_tokens.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 10000\n",
      "Val dataset size is 1314\n",
      "Test dataset size is 7532\n",
      "Total number of tokens in train dataset is 3433739\n",
      "Total number of *unique* tokens in train dataset is 135791\n"
     ]
    }
   ],
   "source": [
    "# First, download datasets from here\n",
    "# Use your NYU account\n",
    "#https://drive.google.com/open?id=1eR2LFI5MGliHlaL1S2nsX4ouIO1k_ip2\n",
    "#https://drive.google.com/open?id=133QCWbiz_Xc7Qm4r6t-fJP1K669xjNlM\n",
    "#https://drive.google.com/open?id=1SuUIUpJ1iznU707ktkpnEGSwt_XIqOYp\n",
    "#https://drive.google.com/open?id=1UQsrZ2LVfcxdxxa47344fMs_qvya72KR\n",
    "\n",
    "# Then, load preprocessed train, val and test datasets\n",
    "train_data_tokens = pkl.load(open(\"train_data_tokens.p\", \"rb\"))\n",
    "all_train_tokens = pkl.load(open(\"all_train_tokens.p\", \"rb\"))\n",
    "\n",
    "val_data_tokens = pkl.load(open(\"val_data_tokens.p\", \"rb\"))\n",
    "test_data_tokens = pkl.load(open(\"test_data_tokens.p\", \"rb\"))\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_tokens)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_tokens)))\n",
    "\n",
    "print (\"Total number of tokens in train dataset is {}\".format(len(all_train_tokens)))\n",
    "print (\"Total number of *unique* tokens in train dataset is {}\".format(len(set(all_train_tokens))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulary\n",
    "\n",
    "Now, we are going to create the vocabulary of most common 10,000 tokens in the training set. Remember that we will add special tokens `<unk>` and `<pad>` to the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "max_vocab_size = 10000\n",
    "# save index 0 for unk and 1 for pad, standard\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "token2id, id2token = build_vocab(all_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 7451 ; token regions\n",
      "Token regions; token id 7451\n"
     ]
    }
   ],
   "source": [
    "# Lets check the dictionary by loading random token from it\n",
    "\n",
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 10000\n",
      "Val dataset size is 1314\n",
      "Test dataset size is 7532\n"
     ]
    }
   ],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n",
    "\n",
    "train_data_indices = token2index_dataset(train_data_tokens)\n",
    "val_data_indices = token2index_dataset(val_data_tokens)\n",
    "test_data_indices = token2index_dataset(test_data_tokens)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize a random tokenized training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'jschief@finbol.toppoint.de', 'joerg', 'schlaeger', '\\n', 'subject', 're', 'difference', 'between', 'vlb', 'and', 'isa', 'eisa', '\\n', 'distribution', 'world', '\\n', 'organization', 'myself', '\\n', 'lines', '24', '\\n\\n', 'hurley@epcot.spdc.ti.com', 'writes', 'in', 'article', '1993apr14.090534.6892@spdc.ti.com', '\\n', '\\n', 'what', 'about', 'vlb', 'and', 'a', '486dx50', '  ', 'does', 'the', 'local', 'bus', 'still', 'run', 'at', '33mhz', 'or', 'does', '\\n', 'it', 'try', 'to', 'run', 'at', '50mhz', '\\n', '\\n', '\\n', 'brian', '\\n', '\\n', '\\n', 'hi', '\\n', 'vlb', 'is', 'defined', 'for', '3', 'cards', 'by', '33mhz', '\\n', 'and', '2', 'cards', 'by', '40mhz', '\\n\\n', 'there', 'are', 'designs', 'with', '50mhz', 'and', '2', 'vlb', 'slots', '\\n', 's.', \"c't\", '9.92', '10.92', '11.92', '\\n\\n', '50mhz', 'and', '2', 'slots', 'are', 'realy', 'difficult', 'to', 'design', '\\n\\n', 'better', 'oss', 'os/2', 'ix', 'are', 'able', 'to', 'handle', 'more', 'than', '16', 'mb', 'of', 'dram', '\\n', 'if', 'you', 'use', 'eisa', 'bus', '\\n', 'has', 'someone', 'experience', 'with', 'vlb', '\\n', 'i', 'think', 'of', 'scsi', 'vlb', 'busmaster', 'the', 'problem', 'is', 'the', '16bit', 'floppy', 'dma', '\\n', 'controller', 'which', 'is', 'unable', 'to', 'reach', 'more', 'than', '16', 'mb', '\\n', 'joerg', '\\n']\n",
      "[17, 1, 1, 1, 2, 34, 56, 625, 244, 2352, 8, 1702, 2475, 2, 143, 149, 2, 38, 747, 2, 36, 470, 9, 1, 58, 11, 63, 1, 2, 2, 42, 54, 2352, 8, 7, 1, 35, 78, 3, 452, 745, 179, 290, 39, 8662, 30, 78, 2, 14, 294, 5, 290, 39, 8328, 2, 2, 2, 789, 2, 2, 2, 673, 2, 2352, 12, 1797, 15, 126, 936, 37, 8662, 2, 8, 97, 936, 37, 1, 9, 44, 20, 4437, 24, 8328, 8, 97, 2352, 4171, 2, 1199, 1, 1, 1, 1, 9, 8328, 8, 97, 4171, 20, 1, 1188, 5, 900, 9, 201, 1, 1991, 1, 20, 369, 5, 1513, 75, 96, 320, 598, 6, 4822, 2, 31, 16, 102, 2475, 745, 2, 60, 235, 684, 24, 2352, 2, 10, 100, 6, 522, 2352, 1, 3, 167, 12, 3, 1, 1233, 3816, 2, 928, 72, 12, 2844, 5, 2235, 75, 96, 320, 598, 2, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "rand_training_example = random.randint(0, len(train_data) - 1)\n",
    "print (train_data_tokens[rand_training_example])\n",
    "print(train_data_indices[rand_training_example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Write a index2token_dataset() function which takes in a the indices and returns back actual tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NewsGroupDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NewsGroupDataset(train_data_indices, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n",
      "146\n",
      "200\n",
      "139\n",
      "194\n"
     ]
    }
   ],
   "source": [
    "### Let's look at the number of tokens in the first few datapoints\n",
    "for i in range(5):\n",
    "    print(train_dataset[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [17, 1, 142, 25, 45, 241, 2, 34, 42, 275, 12, 19, 2, 94, 84, 91, 1, 2, 38, 83, 6, 2792, 601, 1645, 2, 36, 301, 380, 10, 29, 1218, 31, 156, 70, 44, 108, 7993, 67, 18, 19, 275, 10, 639, 2, 3, 87, 253, 14, 29, 7, 1, 2200, 275, 1123, 5, 21, 17, 3, 1266, 1, 2, 813, 9605, 14, 29, 316, 7, 1, 3, 3616, 79, 170, 461, 11, 1309, 2, 3, 785, 6988, 29, 1773, 17, 3, 765, 6, 3, 695, 19, 12, 2, 47, 10, 88, 31, 156, 40, 1, 7, 880, 272, 1005, 2655, 184, 2, 6, 2527, 142, 19, 275, 12, 228, 613, 30, 793, 393, 16, 2, 23, 18, 19, 1, 370, 275, 174, 270, 189, 9, 198, 2, 2564, 107, 856, 1267, 5, 16, 37, 62, 6685, 1, 856, 2058];\n",
      "y 7\n"
     ]
    }
   ],
   "source": [
    "## example output\n",
    "\n",
    "print(\"x {};\\ny {}\".format(train_dataset[0][0], train_dataset[0][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a **collate function** so that when we have it in batches, all the sentences have the same length. We decide to keep a `MAX_SENTENCE_LENGTH` and if the sentence has fewer tokens, append the rest with zero and if the sentence has more tokens, chop it all at `MAX_SENTENCE_LENGTH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newsgroup_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list), torch.LongTensor(label_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = NewsGroupDataset(val_data_indices, val_targets)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = NewsGroupDataset(test_data_indices, test_targets)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  17,    1,    2,  ...,  980,    6,    1],\n",
      "        [  17, 5636,  449,  ..., 1844,    4,    1],\n",
      "        [  17, 3694,  914,  ...,  115,   31,   44],\n",
      "        ...,\n",
      "        [  17, 5414, 1284,  ...,    0,    0,    0],\n",
      "        [  17, 4259,  514,  ...,  161,   11,    7],\n",
      "        [  17,    1, 6179,  ...,  248, 1354,  682]])\n",
      "tensor([14, 18,  0,  3,  0, 15, 16,  8, 14, 14,  6, 15,  8, 15,  8,  8,  1,  8,\n",
      "        17, 19, 16,  0, 15, 14,  3, 16, 16,  2,  9, 17, 18,  1])\n"
     ]
    }
   ],
   "source": [
    "### checking your data loader\n",
    "\n",
    "for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "    print(data)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Words model in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will implement a Bag of Words in PyTorch -- as an `nn.Module`.\n",
    "\n",
    "A `nn.Module` can really be any function, but it is often used to implement layers, functions and models. Note that you can also nest modules.\n",
    "\n",
    "Importantly, modules need to have their `forward()` method overridden, and very often you will want to override the `__init__` method as well. \n",
    "\n",
    "The `__init__` method sets up the module. This is also often where the internal modules and parameters are initialized.\n",
    "\n",
    "The `forward` method defines what happens when you *apply* the module.\n",
    "\n",
    "In the background, PyTorch makes use of your code in the forward method and determines how to implement back-propagation with it - but all you need to do is to define the forward pass!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import torch related libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BagOfWords(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfWords classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(BagOfWords, self).__init__()\n",
    "        # pay attention to padding_idx \n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim,20)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        \n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "     \n",
    "        # return logits\n",
    "        out = self.linear(out.float())\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 100\n",
    "model = BagOfWords(len(id2token), emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10002, 100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10002, 100])\n",
      "torch.Size([20, 100])\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "for x in model.parameters():\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in our Bag of Words model we haven't applied softmax to the output of linear layer. Why?\n",
    "We use `nn.CrossEntropyLoss()` to train. From pytorch documentation for `nn.CrossEntropyLoss()` ( https://pytorch.org/docs/stable/nn.html ) - this criterion combines `nn.LogSoftmax()` and `nn.NLLLoss()` in one single class. So, this is actually exactly the same as minimizing the log likelihood after applying softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10002, 100])\n",
      "torch.Size([20, 100])\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "for x in model.parameters():\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.4264e-02, -5.5181e-02,  7.5035e-02,  7.0315e-02, -2.6792e-01,\n",
      "         -8.8072e-02, -2.5678e-02, -2.3645e-02,  5.9957e-02,  1.5854e-01,\n",
      "         -3.3451e-02,  1.2588e-01,  1.0733e-01, -4.7365e-02,  6.3915e-02,\n",
      "         -2.4506e-02,  2.4604e-02, -2.4014e-02,  1.1208e-01,  1.6177e-01],\n",
      "        [ 7.8916e-02, -1.1241e-01, -9.2073e-02,  2.0988e-03, -2.0726e-01,\n",
      "         -2.2027e-02, -3.5887e-02,  4.0107e-02,  1.1785e-02, -2.8086e-02,\n",
      "         -2.8415e-02,  1.3495e-01,  1.4997e-01, -6.3068e-02,  1.3471e-02,\n",
      "         -9.9768e-02, -5.5491e-02,  5.4752e-03, -1.2338e-02,  1.5244e-01],\n",
      "        [ 5.4201e-02, -2.2008e-02, -2.3583e-02,  8.8713e-02, -3.4194e-01,\n",
      "         -8.4168e-02,  1.4889e-02, -1.7220e-02, -7.6815e-02,  1.9945e-01,\n",
      "         -1.9468e-02,  2.5141e-01,  3.1136e-01, -1.1450e-01,  8.1503e-02,\n",
      "          3.6845e-02, -1.5605e-02, -4.2798e-02,  1.8630e-01,  1.5492e-01],\n",
      "        [-2.0899e-02, -1.0933e-01, -4.8852e-02,  8.8207e-02, -3.3929e-01,\n",
      "         -1.6393e-01,  8.2652e-02, -6.0770e-02,  3.1442e-02,  1.6582e-01,\n",
      "          4.3343e-02,  1.8292e-01,  1.9062e-01, -1.1325e-01,  1.2427e-01,\n",
      "          5.4321e-02, -4.3627e-03, -6.0232e-02,  1.0209e-01,  2.0209e-01],\n",
      "        [-1.4366e-03, -5.2616e-02, -1.9381e-02,  1.8109e-02, -2.0023e-01,\n",
      "         -5.0511e-02, -4.2953e-02, -1.0765e-01, -3.2792e-02,  2.1932e-01,\n",
      "         -2.8066e-02,  1.5787e-01,  2.6968e-01, -8.3282e-02,  1.1296e-01,\n",
      "          7.0043e-02, -2.2550e-02, -9.3434e-02,  7.6570e-02,  1.1021e-01],\n",
      "        [-3.0635e-02, -7.3585e-02,  4.1284e-02,  1.3245e-02, -3.4422e-01,\n",
      "         -1.5558e-02, -5.6819e-02, -6.3220e-02, -2.7885e-03,  1.1712e-01,\n",
      "          8.4940e-02,  1.5338e-01,  1.6348e-01, -8.3581e-02,  2.0217e-01,\n",
      "          6.3259e-02,  2.3469e-02,  6.1122e-02,  1.0123e-01,  1.3886e-01],\n",
      "        [ 8.1484e-02, -9.7548e-02,  2.3914e-02, -3.4812e-02, -2.4666e-01,\n",
      "         -8.0394e-02, -8.8119e-02, -1.1439e-01, -7.3685e-02,  1.3197e-01,\n",
      "         -8.1124e-02,  8.4932e-02,  2.5245e-01, -5.7575e-02,  1.2575e-01,\n",
      "          1.1701e-02, -4.6042e-02, -3.2903e-02,  4.4678e-02,  1.0888e-01],\n",
      "        [ 9.5017e-02, -6.8840e-02, -6.7112e-02,  3.6532e-02, -3.4034e-01,\n",
      "         -1.1262e-01, -1.2492e-02, -1.0955e-01,  4.9369e-02,  9.0599e-03,\n",
      "          2.0292e-02,  1.5851e-01,  2.8651e-01, -8.1784e-02,  1.2968e-01,\n",
      "         -2.0135e-02, -5.2123e-02, -2.7725e-02,  7.1949e-02,  1.4987e-01],\n",
      "        [ 9.6313e-02, -4.2122e-02, -8.9712e-02,  2.2231e-02, -2.7709e-01,\n",
      "         -1.2085e-02, -1.5446e-02, -6.4500e-02,  5.0512e-02,  1.6102e-01,\n",
      "          3.2518e-02,  1.5456e-01,  2.4745e-01, -4.8148e-02,  1.5678e-01,\n",
      "         -7.4888e-02,  4.5457e-03,  8.9706e-03,  1.4280e-01,  1.7972e-01],\n",
      "        [-4.4802e-02, -1.3641e-01, -1.6188e-01,  1.8270e-02, -1.3056e-01,\n",
      "         -8.1413e-02,  7.5406e-02, -5.9142e-02, -1.1317e-01,  1.1910e-01,\n",
      "         -1.2958e-02,  9.6546e-02,  1.8182e-01, -1.5216e-01,  7.5307e-02,\n",
      "         -7.2805e-02,  5.0605e-02,  3.3137e-02,  1.9736e-01,  2.6406e-01],\n",
      "        [ 1.2034e-02,  8.5567e-04,  3.1123e-02,  1.0867e-01, -4.1022e-01,\n",
      "         -9.4419e-02, -1.8206e-02, -3.3635e-02, -7.5302e-02,  9.0031e-02,\n",
      "         -2.1812e-02,  2.1550e-01,  2.7013e-01, -1.6863e-01,  2.3592e-02,\n",
      "          1.8745e-02, -1.8720e-02, -6.5598e-03,  1.8712e-01,  1.6856e-01],\n",
      "        [ 8.5721e-02, -7.8583e-02, -1.1012e-01, -6.7227e-03, -2.4743e-01,\n",
      "         -2.6936e-02, -7.2767e-02, -6.1036e-02, -5.7605e-02,  1.1421e-01,\n",
      "         -7.7710e-05,  7.8830e-02,  3.4277e-01, -6.2625e-02,  7.1601e-02,\n",
      "          3.1491e-03, -1.6221e-02, -1.5561e-01,  9.5287e-02,  9.2401e-02],\n",
      "        [ 5.8694e-02,  4.8779e-02, -5.0233e-02,  1.8288e-02, -3.3417e-01,\n",
      "         -1.4558e-01, -6.7609e-02, -8.6703e-02,  7.3615e-02,  1.0009e-01,\n",
      "          5.5343e-02,  9.1330e-02,  1.6812e-01, -8.0860e-02,  8.0341e-02,\n",
      "          9.9061e-03,  5.0742e-02, -5.0359e-02,  6.7560e-02,  1.4641e-01],\n",
      "        [ 8.9961e-02, -2.3696e-02,  8.9373e-03, -3.2911e-02, -2.7496e-01,\n",
      "         -1.2888e-01, -5.5130e-02, -8.4263e-02, -5.8949e-02,  1.5829e-01,\n",
      "          1.2276e-02,  1.5499e-01,  2.6846e-01, -9.0391e-02,  7.5908e-02,\n",
      "          1.3473e-02,  4.5773e-02, -7.8754e-02,  1.1148e-01,  1.3376e-01],\n",
      "        [ 1.0266e-01, -3.9678e-02, -4.9405e-02, -7.7127e-03, -2.7210e-01,\n",
      "         -6.1362e-02, -2.6055e-02, -2.2412e-02,  1.9029e-02,  1.5087e-01,\n",
      "          7.4293e-03,  1.1861e-01,  2.4432e-01, -4.3589e-02,  5.1371e-02,\n",
      "         -4.7348e-02,  4.5684e-02, -4.3819e-02,  7.1710e-02,  4.2072e-02],\n",
      "        [ 6.1367e-02, -1.1818e-02, -8.3456e-02,  7.1685e-02, -2.7207e-01,\n",
      "         -9.0070e-02, -2.1974e-02, -1.0657e-01, -8.3865e-02,  1.6808e-01,\n",
      "         -2.9388e-02,  1.4851e-01,  3.8805e-01, -7.0351e-02,  1.0329e-01,\n",
      "         -3.1301e-02, -7.9324e-02,  2.5749e-02,  1.8226e-01,  1.9643e-01],\n",
      "        [-1.4077e-02, -9.2983e-02, -6.6115e-02,  7.3548e-02, -1.9365e-01,\n",
      "         -5.5756e-02,  8.3296e-02, -9.1674e-02, -5.2649e-02,  4.5183e-02,\n",
      "         -8.5597e-02,  1.3171e-01,  2.5304e-01, -2.2273e-01,  4.3559e-02,\n",
      "         -3.2741e-02,  5.6089e-02, -7.6891e-02,  1.0907e-01,  1.1273e-01],\n",
      "        [ 4.1419e-02, -7.0314e-02,  4.9552e-02, -9.2556e-04, -2.5771e-01,\n",
      "         -7.4974e-02, -4.8612e-02, -1.2533e-01, -9.0249e-03,  1.4649e-01,\n",
      "          5.0389e-03,  2.4152e-01,  1.9434e-01, -2.6763e-02,  1.5259e-01,\n",
      "          9.6129e-02, -9.8345e-03,  6.5339e-03,  9.7559e-02,  1.6562e-01],\n",
      "        [ 4.5120e-02, -1.1017e-01,  3.8679e-02,  1.4154e-01, -3.2171e-01,\n",
      "         -4.4848e-02, -2.1395e-02, -1.5711e-01, -3.2515e-02,  1.7777e-01,\n",
      "          1.0597e-02,  2.6794e-01,  2.4049e-01, -1.4038e-01,  7.4126e-02,\n",
      "          1.1306e-02, -5.9649e-02, -6.2790e-02,  1.1849e-01,  1.7258e-01],\n",
      "        [ 8.6201e-02, -1.0970e-01, -4.0989e-02, -7.2980e-02, -2.5779e-01,\n",
      "         -3.4541e-02,  3.3954e-03, -1.3571e-01, -4.1293e-02,  1.0595e-01,\n",
      "          6.7022e-03,  1.0762e-01,  1.3271e-01, -1.1676e-01,  1.8585e-01,\n",
      "          1.4617e-01,  9.5076e-02, -6.3401e-02,  6.4595e-02,  1.3716e-01],\n",
      "        [ 5.8203e-02, -1.7721e-02, -1.0962e-01,  4.2031e-02, -2.5560e-01,\n",
      "         -1.0505e-01,  7.5568e-02, -2.3120e-02,  4.1652e-02,  1.9456e-01,\n",
      "         -1.4784e-02,  1.2715e-01,  2.3360e-01, -1.0517e-01,  1.3141e-01,\n",
      "         -3.8767e-02, -2.2132e-02, -4.0317e-02,  1.7608e-01,  1.0970e-01],\n",
      "        [ 2.4587e-02, -1.1173e-01, -1.1944e-01, -4.5904e-02, -2.1925e-01,\n",
      "         -1.0885e-01,  3.5998e-02,  1.0337e-02, -1.9833e-04,  4.2822e-02,\n",
      "         -2.1886e-02,  1.1560e-01,  1.6475e-01, -7.6860e-02,  7.5519e-02,\n",
      "          2.1973e-02,  6.6905e-02, -1.0108e-01,  5.3675e-02,  6.1150e-02],\n",
      "        [ 9.9557e-02, -3.5540e-02,  1.9729e-02,  8.8620e-02, -4.0700e-01,\n",
      "         -1.3086e-01, -1.1536e-03, -1.5305e-01,  4.1434e-02,  1.4041e-01,\n",
      "         -1.1382e-01,  2.0188e-01,  2.6555e-01, -6.0229e-02,  1.1859e-01,\n",
      "         -4.5216e-02,  4.5825e-02, -3.4958e-02,  2.8567e-01,  3.0074e-01],\n",
      "        [ 6.1241e-02, -2.4862e-02, -5.3467e-02,  1.0905e-01, -3.1019e-01,\n",
      "         -8.0176e-02, -4.3217e-02, -1.0856e-01,  1.3350e-01,  9.8473e-02,\n",
      "         -6.4916e-02,  6.0136e-02,  1.6786e-01, -1.2500e-01,  2.2683e-02,\n",
      "         -1.3777e-01,  4.1100e-02, -3.6510e-02,  4.8968e-02,  2.0791e-01],\n",
      "        [-6.2696e-02,  5.4113e-02,  1.0945e-01, -4.4181e-02, -2.9075e-01,\n",
      "         -2.5775e-01,  5.3815e-02,  6.2032e-02,  4.5606e-02,  5.5767e-02,\n",
      "         -7.3938e-02,  1.7124e-01,  1.0138e-01, -1.5581e-01,  6.2535e-02,\n",
      "         -6.8342e-02,  9.1858e-02,  3.9017e-03,  1.2829e-01,  3.2764e-01],\n",
      "        [ 7.4952e-02, -1.0275e-01, -1.9026e-01,  1.9899e-02, -1.9285e-01,\n",
      "         -8.0336e-02,  2.1108e-02, -1.9866e-02, -1.3148e-02,  1.6781e-01,\n",
      "         -3.7712e-02,  8.4335e-02,  2.5728e-01, -1.1558e-01,  5.7057e-02,\n",
      "         -5.3699e-04, -4.3009e-02, -2.5842e-02,  9.0531e-03,  1.6381e-01],\n",
      "        [ 2.3977e-02, -5.2449e-02,  1.3231e-01,  1.0948e-01, -3.2021e-01,\n",
      "         -1.7780e-01, -7.7583e-04,  6.3620e-02,  9.6736e-02,  6.7070e-02,\n",
      "         -1.0008e-02,  1.7719e-01,  7.9964e-02, -1.3438e-01,  1.6973e-02,\n",
      "          1.0857e-01,  3.6209e-03, -1.3879e-01,  9.4422e-02,  1.3306e-01],\n",
      "        [ 7.0147e-03, -7.5605e-02, -3.2144e-02, -5.2972e-02, -1.5425e-01,\n",
      "         -1.1208e-01, -2.6707e-02,  2.2670e-02, -4.7901e-02,  1.1227e-01,\n",
      "         -4.9543e-02,  1.4806e-01,  1.4954e-01, -6.8834e-02,  4.9370e-02,\n",
      "          2.5015e-02, -7.4302e-04, -4.8785e-02, -2.2755e-02,  1.4254e-01],\n",
      "        [ 3.7309e-02, -3.1737e-02,  1.2388e-01,  6.5705e-02, -4.6093e-01,\n",
      "         -1.1516e-01, -3.6040e-03, -1.1979e-01,  1.2172e-02,  1.1147e-01,\n",
      "          3.9219e-02,  2.6438e-01,  2.3126e-01, -9.9529e-02,  1.7253e-01,\n",
      "          1.0563e-01, -4.1632e-02, -8.6192e-02,  1.3309e-01,  2.8740e-01],\n",
      "        [ 3.1016e-02, -6.8229e-02, -1.2621e-02,  5.7139e-02, -3.2159e-01,\n",
      "         -7.2464e-02,  5.8702e-02, -5.2585e-02, -4.2520e-02,  8.9959e-02,\n",
      "         -2.3099e-02,  2.5895e-01,  2.7746e-01, -1.1177e-01,  1.0582e-01,\n",
      "         -4.0927e-02,  7.6874e-02,  1.2789e-02,  1.4412e-01,  1.6856e-01],\n",
      "        [ 3.7434e-02, -1.2313e-01, -1.4075e-01,  6.2776e-03, -1.7452e-01,\n",
      "         -2.1004e-02,  4.7581e-02, -5.0173e-02,  1.9169e-02,  1.3534e-01,\n",
      "         -7.4663e-02,  1.3335e-01,  1.8228e-01, -7.2713e-02,  6.5468e-02,\n",
      "          4.2422e-03,  4.2092e-02, -6.0635e-02,  1.0067e-01,  1.5393e-01],\n",
      "        [-5.3802e-03, -6.8391e-02, -4.1354e-02,  7.0626e-02, -2.6952e-01,\n",
      "         -7.8123e-02,  2.4683e-02, -4.4729e-02, -3.1033e-02,  1.7259e-01,\n",
      "         -5.7828e-02,  2.0028e-01,  2.0229e-01, -4.3817e-02,  7.5529e-02,\n",
      "          2.5316e-02, -1.5628e-02, -2.9918e-02,  8.0111e-02,  1.6315e-01]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([ 9,  6,  5,  6, 12, 17,  0,  9,  1,  5,  2, 14,  4, 12, 13, 10,  0, 10,\n",
      "         1,  1, 11,  7,  1, 19,  5, 15,  6,  4,  4,  1,  7,  4])\n",
      "tensor([[ 9.7701e-02, -1.4957e-01, -1.7507e-02, -3.8104e-02, -3.2830e-01,\n",
      "          7.9334e-03,  2.1598e-02, -9.7938e-02, -8.1691e-02, -1.4277e-02,\n",
      "          5.1656e-02,  2.5312e-02,  3.2575e-01, -4.3669e-02,  2.9145e-01,\n",
      "         -9.5951e-02,  1.4180e-02,  3.6348e-02,  2.0836e-01,  1.7127e-01],\n",
      "        [ 5.1754e-02, -3.5712e-02, -7.1064e-02, -1.9250e-02, -1.9604e-01,\n",
      "         -1.2257e-01,  6.3233e-02, -1.4785e-02, -4.4149e-03,  1.1455e-01,\n",
      "         -4.9666e-02,  1.2105e-01,  1.9830e-01, -1.3084e-01,  5.1446e-02,\n",
      "         -3.0897e-02, -3.5080e-02, -3.7621e-02,  2.4582e-02, -8.9014e-04],\n",
      "        [ 4.2119e-02, -8.4506e-02, -4.7426e-02, -2.7122e-04, -2.5535e-01,\n",
      "         -7.2121e-02,  3.5390e-02, -1.8948e-03, -4.2448e-02,  9.7242e-02,\n",
      "         -7.7691e-02,  2.5851e-01,  2.7964e-01, -5.0478e-02,  4.7091e-02,\n",
      "          3.5788e-02,  3.5633e-02, -3.0307e-02,  5.4996e-02,  1.7365e-01],\n",
      "        [-1.7156e-02, -7.0781e-02,  5.3288e-03, -6.4910e-03, -2.0772e-01,\n",
      "         -1.5415e-01, -6.9367e-02,  4.0433e-02,  8.3575e-02,  7.0927e-02,\n",
      "         -1.0358e-01,  1.4817e-01,  1.8096e-01, -8.0047e-02,  7.3939e-02,\n",
      "         -8.0334e-02, -2.1076e-04, -1.5769e-02,  7.0093e-02,  1.2556e-01],\n",
      "        [ 2.3514e-02, -9.6208e-02,  8.3868e-02,  1.2819e-01, -4.7338e-01,\n",
      "         -6.6415e-02, -4.3598e-02, -1.2480e-01, -7.1105e-02,  2.0254e-01,\n",
      "         -7.9204e-02,  1.0919e-01,  2.4776e-01, -8.9041e-02,  1.6434e-01,\n",
      "          3.1180e-02, -1.7266e-02, -8.1177e-02,  1.8601e-01,  3.4805e-01],\n",
      "        [ 1.0076e-02, -9.7829e-02, -8.9342e-02,  4.1610e-02, -2.4014e-01,\n",
      "         -1.2550e-01, -4.1935e-02, -1.6638e-01,  1.1096e-03,  1.5233e-01,\n",
      "         -6.1201e-02,  1.0304e-01,  2.2761e-01, -8.8896e-02,  8.3794e-02,\n",
      "          4.4379e-02,  7.0249e-02, -9.1356e-02,  1.3035e-01,  1.5639e-01],\n",
      "        [ 3.0380e-02,  2.6270e-02, -1.6591e-02,  8.4817e-02, -3.0142e-01,\n",
      "         -1.4923e-01, -6.3200e-02, -2.1998e-02, -1.7716e-02,  6.7305e-02,\n",
      "         -1.1730e-02,  1.5527e-01,  1.3527e-01, -5.3312e-02,  4.4728e-02,\n",
      "         -3.6456e-02, -3.8216e-02, -2.4770e-02,  1.3798e-01,  1.9463e-01],\n",
      "        [ 1.1744e-01,  2.3760e-02,  8.5672e-02,  1.7061e-01, -4.8872e-01,\n",
      "         -1.1326e-01,  4.1178e-02, -1.1623e-01,  2.5401e-02,  1.7968e-01,\n",
      "          2.9208e-02,  2.5348e-01,  2.2451e-01, -1.0036e-01,  4.1668e-02,\n",
      "         -5.8807e-02, -6.1010e-02,  1.5443e-02,  2.8344e-01,  3.7796e-01],\n",
      "        [-1.8701e-03, -3.0681e-02, -4.4027e-02, -6.8621e-02, -2.4063e-01,\n",
      "         -1.0381e-01, -1.8957e-02, -5.8976e-02, -7.8858e-02,  8.9295e-02,\n",
      "         -1.0512e-02,  1.1951e-01,  1.6945e-01, -1.0809e-01,  1.7121e-01,\n",
      "         -6.6774e-02,  4.1718e-02, -7.4341e-02,  8.6451e-02,  1.2805e-01],\n",
      "        [ 9.8852e-02, -1.4691e-03, -5.3462e-02,  5.0542e-02, -2.3754e-01,\n",
      "         -1.1958e-01,  6.0862e-02, -2.0885e-02,  9.1755e-02,  1.3257e-01,\n",
      "         -1.9301e-02,  9.0261e-02,  1.9199e-01, -1.1771e-01,  7.6962e-02,\n",
      "         -1.6620e-02, -8.4286e-02, -1.0457e-01,  6.7402e-02,  1.7396e-01],\n",
      "        [ 7.7353e-03, -7.8647e-02,  2.0234e-02, -6.7935e-02, -2.8613e-01,\n",
      "         -1.3473e-01,  2.1372e-02,  4.3153e-02,  1.4736e-02,  1.6809e-01,\n",
      "         -1.3555e-02,  1.9386e-01,  1.3510e-01, -1.0258e-01,  2.9336e-02,\n",
      "          8.1492e-03, -4.2657e-03, -5.3547e-02,  1.1100e-01,  9.8136e-02],\n",
      "        [ 1.2275e-01,  2.9712e-02, -1.2782e-01,  1.0643e-01, -2.0853e-01,\n",
      "         -9.1844e-03,  4.0227e-02, -5.7241e-03, -5.0243e-04,  1.7153e-01,\n",
      "          3.1620e-03,  1.7281e-01,  2.6010e-01, -7.6622e-02, -3.9835e-02,\n",
      "         -5.2505e-02, -2.5004e-02, -8.6026e-02,  1.0305e-01,  1.5915e-02],\n",
      "        [ 4.7333e-02, -1.2560e-01, -1.1245e-01, -1.2156e-01, -1.4090e-01,\n",
      "         -6.8955e-02,  9.9214e-02, -7.5891e-02,  3.0609e-02,  9.6858e-02,\n",
      "          2.5170e-02,  5.6861e-02,  2.1567e-01, -1.9250e-01,  2.2765e-01,\n",
      "          1.2965e-01,  5.6606e-02, -9.1587e-02,  2.3272e-02,  1.1959e-01],\n",
      "        [ 3.7753e-02, -1.3579e-01, -5.9813e-02, -5.8961e-04, -2.3878e-01,\n",
      "         -4.9523e-02,  5.2436e-02, -1.8654e-01, -1.3048e-02,  5.1118e-02,\n",
      "         -7.1170e-02,  1.3146e-01,  2.2283e-01, -1.7618e-01,  2.2561e-01,\n",
      "         -4.9139e-03, -6.5318e-02,  5.8542e-03,  6.7347e-02,  2.9377e-01],\n",
      "        [ 5.0709e-02, -7.6478e-02,  5.9403e-02,  1.6472e-01, -3.6975e-01,\n",
      "         -7.8177e-02, -5.9552e-02, -2.0912e-02, -1.7936e-02,  1.2168e-01,\n",
      "         -6.8587e-02,  2.4023e-01,  2.5228e-01, -8.5816e-02,  1.2826e-01,\n",
      "         -3.0975e-02, -1.3924e-02, -6.0223e-02,  1.2608e-01,  1.7445e-01],\n",
      "        [ 4.0551e-02, -1.0524e-01, -4.2948e-02,  2.6781e-02, -1.6296e-01,\n",
      "         -5.9851e-02,  1.5576e-02, -3.7679e-02, -1.5924e-02,  1.9557e-01,\n",
      "         -9.8632e-02,  1.2773e-01,  2.3667e-01, -8.8500e-02, -7.3013e-04,\n",
      "          1.2621e-02, -3.7283e-02, -6.1566e-02,  8.4964e-02,  5.2609e-02],\n",
      "        [ 1.2388e-01, -1.5839e-02, -1.9494e-02,  7.3435e-02, -4.3174e-01,\n",
      "         -9.7532e-02, -2.0687e-02, -7.1705e-02, -2.1317e-02,  1.1641e-01,\n",
      "          9.0524e-03,  2.4110e-01,  2.9054e-01, -7.7804e-02,  6.4398e-02,\n",
      "         -2.1766e-02,  6.9917e-02,  5.1180e-02,  2.1373e-01,  1.7767e-01],\n",
      "        [-6.9621e-02,  2.2359e-02, -4.8533e-02,  5.3502e-02, -2.8133e-01,\n",
      "         -1.0653e-01,  3.6550e-02,  1.1401e-01,  1.3799e-02,  9.3388e-02,\n",
      "         -1.7264e-01,  1.7333e-01,  1.1968e-01, -7.3700e-02, -3.8214e-02,\n",
      "         -1.1920e-01, -4.7292e-02,  5.3283e-02,  8.4663e-02,  1.0657e-01],\n",
      "        [-5.6723e-02, -7.9759e-02,  1.3851e-02, -4.9334e-02, -3.1192e-01,\n",
      "         -1.4422e-01, -2.0911e-02, -1.1090e-02,  5.9220e-02,  8.4020e-02,\n",
      "          5.2129e-02,  1.1852e-01,  1.0336e-01, -1.8530e-01,  1.0285e-01,\n",
      "          9.6852e-02,  8.9623e-02, -1.0340e-01,  3.3844e-02,  1.4421e-01],\n",
      "        [-1.7905e-02, -1.1419e-01, -6.7862e-02,  4.9828e-02, -2.6689e-01,\n",
      "         -1.1251e-01,  1.5497e-02, -7.0925e-02,  1.2709e-02,  1.0928e-01,\n",
      "         -4.2666e-02,  1.5557e-01,  1.7098e-01, -7.7228e-02,  8.8104e-02,\n",
      "         -3.6912e-03,  4.5306e-02, -4.5468e-02,  9.2602e-02,  1.8870e-01],\n",
      "        [ 4.6348e-02, -1.8109e-02, -1.0901e-01,  2.1879e-02, -5.1126e-02,\n",
      "         -3.7103e-02,  1.0989e-01, -5.5981e-03, -6.9315e-03,  9.5795e-02,\n",
      "         -1.7951e-02,  1.1584e-01,  1.8299e-01, -1.6746e-01,  1.3506e-02,\n",
      "         -9.5128e-02,  1.2197e-01, -4.9009e-02,  1.1635e-01,  1.3427e-02],\n",
      "        [ 6.8226e-02, -4.1406e-02,  2.6292e-02,  4.8221e-02, -3.0311e-01,\n",
      "          3.6343e-02, -1.9202e-02, -9.7485e-02,  1.3549e-02,  1.6266e-01,\n",
      "         -6.1855e-02,  2.1056e-01,  3.0969e-01, -9.2790e-02,  8.3555e-02,\n",
      "         -3.8476e-02, -5.3121e-02, -1.1150e-02,  2.4272e-01,  2.0821e-01],\n",
      "        [ 4.9941e-02, -4.5086e-02, -3.7984e-02, -2.3639e-02, -2.6849e-01,\n",
      "         -9.0493e-02, -2.2905e-02, -1.0181e-01, -6.4908e-04,  8.3301e-02,\n",
      "         -1.0104e-02,  1.3024e-01,  2.6860e-01, -8.8465e-02,  1.6595e-01,\n",
      "          2.4652e-02,  4.0034e-02,  4.3134e-02,  1.5126e-01,  1.4189e-01],\n",
      "        [ 5.6172e-02, -6.5766e-02, -3.7795e-02, -5.2432e-02, -1.9137e-01,\n",
      "         -4.2260e-02,  9.8357e-03, -3.0075e-02,  3.2162e-02,  6.7371e-02,\n",
      "          1.6602e-02,  1.0139e-01,  2.1420e-01, -1.1875e-01,  5.5051e-02,\n",
      "          2.6834e-02, -3.3022e-02, -8.5188e-02, -2.0270e-02,  1.5839e-01],\n",
      "        [ 1.1516e-01, -2.9996e-02,  4.5756e-03,  1.3903e-01, -4.0376e-01,\n",
      "         -8.9078e-02, -3.0125e-02, -1.2783e-01,  1.6619e-02,  2.0821e-01,\n",
      "          4.5861e-02,  1.7625e-01,  2.5571e-01, -9.7944e-02,  6.1026e-02,\n",
      "          6.8477e-02, -5.2065e-03, -4.7313e-02,  2.4442e-01,  2.3660e-01],\n",
      "        [-7.7637e-02, -2.2459e-02, -6.0476e-02, -3.6551e-02, -2.0889e-01,\n",
      "         -8.6417e-02,  5.9403e-03, -1.3602e-01,  2.7372e-02,  1.4313e-01,\n",
      "          5.2222e-02,  8.3773e-02,  2.2858e-01, -1.1191e-01,  1.1263e-01,\n",
      "          1.7118e-01,  1.2091e-01, -1.0153e-01,  8.8929e-02, -1.1007e-04],\n",
      "        [-6.8813e-02, -9.6549e-02, -8.1477e-02, -4.8608e-02, -1.9170e-01,\n",
      "         -1.3268e-01, -3.8588e-02, -9.6289e-02,  4.5182e-02,  1.9953e-01,\n",
      "          6.6330e-03,  6.6047e-02,  2.0936e-01, -1.3427e-01,  6.1721e-02,\n",
      "          1.0464e-01, -2.5720e-02, -1.2428e-01,  1.6654e-02,  2.0180e-02],\n",
      "        [ 3.6860e-02,  4.9970e-03, -7.9513e-02,  3.9557e-02, -3.5539e-01,\n",
      "         -8.4620e-02,  6.0381e-02, -1.5803e-02, -1.1323e-01,  4.4472e-02,\n",
      "         -2.5329e-02,  1.8284e-01,  2.7909e-01, -1.4006e-01,  9.4260e-02,\n",
      "         -1.9346e-02,  4.9639e-02, -4.6646e-02,  1.2923e-01,  2.4884e-01],\n",
      "        [-5.8238e-02, -4.9484e-02,  7.3079e-02,  6.2863e-02, -3.4962e-01,\n",
      "         -2.0008e-01,  2.7806e-02,  1.2508e-01,  1.2170e-01,  1.3456e-01,\n",
      "         -8.0346e-02,  3.2586e-01,  1.1180e-02, -2.9444e-02,  8.8101e-03,\n",
      "          1.0379e-02, -1.7617e-02, -2.9924e-02,  1.0274e-01,  2.7623e-01],\n",
      "        [ 1.1406e-01, -1.0852e-01, -3.2169e-02, -9.2079e-02, -2.4489e-01,\n",
      "         -3.0516e-02,  3.1695e-02,  2.8533e-02,  2.7705e-02,  1.0011e-02,\n",
      "         -5.3404e-02,  8.3778e-02,  2.2769e-01, -4.9009e-02,  9.3324e-02,\n",
      "         -1.8493e-02,  6.0442e-02, -2.0272e-02,  6.2495e-02,  1.5346e-01],\n",
      "        [ 2.0353e-03,  3.3772e-02,  2.9681e-02,  7.7158e-02, -2.6881e-01,\n",
      "         -5.0253e-02, -3.0529e-02, -7.3937e-02, -4.7427e-02,  9.5671e-02,\n",
      "         -4.8498e-02,  2.3031e-01,  2.9831e-01, -1.7752e-01,  3.1678e-03,\n",
      "         -2.7944e-02, -1.0454e-01, -5.3962e-02,  1.0698e-01,  8.8254e-02],\n",
      "        [ 2.3650e-03, -1.3928e-02,  1.2360e-01,  1.1439e-01, -4.4334e-01,\n",
      "         -6.9806e-02, -1.2118e-01, -2.5980e-02,  3.2360e-02,  2.1051e-01,\n",
      "         -7.5970e-02,  1.3457e-01,  2.9907e-01, -2.1316e-02,  1.4601e-01,\n",
      "         -3.7177e-02, -7.0303e-02,  6.9243e-02,  2.6764e-01,  2.7682e-01]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([16, 11,  2,  8,  2, 13,  6, 14,  1, 19, 12, 15,  4, 13,  1,  4,  1,  1,\n",
      "         2,  3,  4,  0, 12, 16,  3,  4,  1, 12, 19,  5,  2,  2])\n",
      "tensor([[ 1.0913e-01,  1.6762e-03, -6.0458e-02, -7.1496e-02, -2.2963e-01,\n",
      "         -1.5833e-01,  9.5811e-02, -1.5890e-03,  2.3460e-02,  1.0252e-01,\n",
      "         -7.2358e-02,  1.5362e-01,  1.9709e-01, -6.1156e-02,  7.0122e-02,\n",
      "         -3.9533e-02,  1.6258e-02,  4.7581e-02,  9.3727e-02,  1.0079e-01],\n",
      "        [ 1.0278e-03, -5.3852e-02, -4.5888e-02, -8.6311e-02, -1.9692e-01,\n",
      "         -2.2587e-01,  1.1307e-01, -1.1021e-02,  6.1080e-02,  1.7263e-01,\n",
      "         -1.3837e-01,  2.2689e-01,  9.7179e-02, -1.6658e-01, -1.9297e-02,\n",
      "          1.2486e-01,  4.5914e-02, -5.8471e-02,  3.5176e-02,  1.2432e-01],\n",
      "        [ 2.8732e-02, -1.0892e-01,  1.1695e-01, -3.9250e-02, -2.1663e-01,\n",
      "         -1.4633e-01, -1.7995e-02, -6.5724e-02, -7.9851e-02,  1.4411e-01,\n",
      "          2.8572e-02,  1.7198e-01,  1.0857e-01, -7.3493e-02,  1.4872e-01,\n",
      "          4.2318e-02, -5.3552e-03, -5.0359e-02,  8.8028e-02,  1.2346e-01],\n",
      "        [ 1.0847e-01, -5.1328e-02, -3.9479e-02,  6.7806e-02, -3.3177e-01,\n",
      "         -8.6985e-02, -3.0095e-02, -2.5252e-02,  1.0292e-03,  1.0869e-01,\n",
      "         -3.2224e-02,  1.9947e-01,  2.2671e-01, -1.1309e-01,  1.3245e-01,\n",
      "         -1.5590e-02,  1.2649e-02, -1.1149e-02,  1.8617e-01,  1.8304e-01],\n",
      "        [ 5.7310e-02, -3.2872e-02, -5.4943e-02,  1.2748e-01, -2.9257e-01,\n",
      "         -6.9274e-02, -1.0513e-01, -4.5683e-02, -1.1084e-02,  1.1354e-01,\n",
      "         -7.3043e-02,  1.2797e-01,  3.5513e-01, -6.7411e-02,  4.3523e-02,\n",
      "         -1.4300e-01,  4.7908e-02, -3.0139e-03,  1.0696e-01,  1.6388e-01],\n",
      "        [ 8.3410e-03, -5.0500e-02,  8.5852e-03,  2.2082e-03, -1.2023e-01,\n",
      "         -9.5092e-02,  6.7599e-02,  4.9926e-03, -5.6780e-02,  1.5036e-01,\n",
      "          2.6968e-02,  1.1545e-01,  2.4380e-01, -1.8637e-01,  1.7095e-01,\n",
      "         -6.6549e-02, -2.9433e-02, -2.4594e-02,  1.3661e-01,  1.2577e-01],\n",
      "        [ 7.1596e-02, -6.8842e-02,  1.5817e-02,  2.0716e-02, -2.2973e-01,\n",
      "         -6.3744e-02, -1.8782e-02, -1.0912e-01, -8.7417e-03,  1.4130e-01,\n",
      "         -3.5009e-02,  8.1150e-02,  1.5385e-01, -7.3679e-02,  1.0403e-01,\n",
      "          2.8771e-02,  3.6394e-02, -7.1977e-02,  5.9556e-02,  1.1852e-01],\n",
      "        [ 7.9471e-02,  8.2996e-04, -1.5311e-01, -3.0659e-02, -1.2958e-01,\n",
      "         -8.7886e-02,  6.3014e-02, -5.3196e-02,  1.0336e-01,  1.4033e-01,\n",
      "         -1.5245e-02,  6.6967e-02,  2.3126e-01, -1.3729e-01,  5.3597e-02,\n",
      "         -4.9832e-02, -8.2335e-03, -1.2053e-01,  6.9622e-02,  1.5659e-01],\n",
      "        [ 7.8426e-02, -1.2076e-01, -5.0651e-02,  1.5555e-02, -2.0590e-01,\n",
      "         -1.1074e-01,  4.5698e-02, -8.9546e-02,  8.8469e-02,  1.3937e-01,\n",
      "          2.0991e-02,  1.6444e-01,  1.9140e-01, -5.7107e-02,  1.1889e-01,\n",
      "         -1.5512e-02,  3.6040e-02,  1.0209e-02,  8.2323e-02,  1.1474e-01],\n",
      "        [-3.1075e-02, -5.2455e-02, -1.3937e-01, -3.8831e-02, -2.4713e-01,\n",
      "         -5.9614e-02,  2.6462e-03, -8.7968e-02, -2.0857e-02,  1.7449e-01,\n",
      "          1.4484e-05,  1.9880e-01,  3.0025e-01, -1.0754e-01,  5.1509e-02,\n",
      "          5.4847e-02, -4.1197e-02, -9.8789e-02,  1.2440e-01,  1.0820e-01],\n",
      "        [ 8.8072e-02, -3.6382e-02, -7.2255e-02,  1.7263e-02, -2.2295e-01,\n",
      "         -1.7000e-01,  1.7997e-02, -6.7148e-02, -1.0823e-02,  7.3174e-02,\n",
      "         -4.2028e-02,  7.6181e-02,  2.2238e-01, -5.3940e-02,  8.3497e-02,\n",
      "          2.5924e-03,  5.7249e-03, -7.4130e-02,  3.9194e-02,  1.1768e-01],\n",
      "        [ 4.0920e-02, -2.8338e-02, -6.3452e-02,  7.1987e-02, -2.8074e-01,\n",
      "         -1.0506e-01,  3.5150e-02, -3.7122e-02, -6.3724e-02,  1.3092e-01,\n",
      "         -7.8832e-02,  1.2866e-01,  2.3143e-01, -1.6952e-01,  1.5706e-01,\n",
      "          9.9181e-03, -1.2958e-01, -1.1210e-02,  1.2394e-01,  1.3589e-01],\n",
      "        [ 1.3367e-01, -1.2255e-01, -1.1382e-01,  3.2475e-02, -2.6867e-01,\n",
      "         -2.3814e-02,  6.8112e-02, -1.1445e-01,  4.0218e-02,  9.0707e-02,\n",
      "          2.6327e-02,  1.1912e-01,  2.4340e-01, -7.6523e-02,  3.3254e-02,\n",
      "          4.2804e-02,  2.9082e-02, -1.5015e-01,  8.0484e-02,  1.9480e-01],\n",
      "        [ 8.4053e-02, -1.0975e-01,  1.7442e-02,  1.1913e-01, -3.6628e-01,\n",
      "         -4.5877e-02, -7.4670e-02, -9.8075e-03, -9.6030e-03,  2.4020e-01,\n",
      "         -8.6687e-03,  1.9618e-01,  2.9269e-01, -1.2296e-01,  1.4983e-01,\n",
      "          2.7084e-02,  8.3011e-02, -4.0220e-02,  1.5614e-01,  2.0380e-01],\n",
      "        [ 7.4517e-02, -1.6299e-02, -1.4474e-02,  4.0445e-03, -2.9362e-01,\n",
      "         -4.2467e-02,  4.5711e-02, -5.2487e-02, -1.3260e-02,  3.5016e-02,\n",
      "         -4.4263e-02,  1.3759e-01,  1.8860e-01, -8.0935e-02,  5.8998e-02,\n",
      "         -7.9661e-03, -3.4777e-03, -4.8322e-03,  1.2207e-01,  2.0562e-01],\n",
      "        [ 6.1835e-03, -2.0393e-02, -1.2246e-01, -1.3182e-01, -1.0298e-01,\n",
      "         -1.4231e-01,  5.7001e-02, -3.5388e-02, -2.8647e-02,  2.5070e-02,\n",
      "         -3.4950e-02,  9.6347e-02,  2.4156e-01, -8.7612e-02,  8.4129e-02,\n",
      "         -2.4049e-02, -8.5732e-03, -6.7063e-02,  5.5043e-02,  9.5533e-02],\n",
      "        [ 1.3359e-01, -6.6328e-02, -1.5861e-02, -4.6380e-03, -3.2169e-01,\n",
      "         -4.0271e-02,  2.7722e-02, -1.0473e-02,  3.9864e-02,  6.4898e-02,\n",
      "         -2.7655e-02,  1.1846e-01,  2.2354e-01, -7.9394e-02,  6.6092e-02,\n",
      "         -3.6741e-02,  4.6849e-02, -4.0194e-02,  2.3105e-02,  7.6970e-02],\n",
      "        [ 3.0675e-02, -4.5451e-02, -2.8098e-02,  5.8679e-02, -3.3694e-01,\n",
      "         -6.1068e-02, -1.1029e-01,  4.9500e-03,  7.3764e-02,  1.1253e-01,\n",
      "         -8.9870e-03,  1.9972e-01,  2.0599e-01, -2.8001e-02,  5.7377e-02,\n",
      "          4.5858e-02, -3.3116e-02, -5.5744e-02,  4.0009e-02,  6.5543e-02],\n",
      "        [ 1.4269e-03, -4.9554e-02, -7.2082e-02,  7.7748e-02, -3.0472e-01,\n",
      "         -6.3754e-02,  4.5148e-02, -6.3746e-02,  8.2437e-02,  1.8795e-01,\n",
      "          6.2922e-03,  2.3350e-01,  2.0434e-01, -9.3331e-02,  6.0200e-02,\n",
      "         -8.7033e-03, -6.9775e-02, -4.4570e-02,  1.3042e-01,  1.5619e-01],\n",
      "        [ 2.2923e-02, -8.5931e-02, -8.8539e-02,  2.8083e-02, -2.5440e-01,\n",
      "         -3.1803e-02,  3.4829e-02, -7.0849e-02, -7.7382e-02,  8.5759e-02,\n",
      "         -1.5535e-02,  1.1399e-01,  2.6777e-01, -1.3629e-01,  1.4597e-01,\n",
      "         -7.0134e-03,  9.2010e-02, -3.4925e-02,  1.4924e-01,  2.3735e-01],\n",
      "        [ 8.5221e-02, -6.8362e-02, -4.7959e-02,  1.0544e-01, -2.2356e-01,\n",
      "         -3.8083e-02, -7.8386e-02, -8.7171e-02,  1.1697e-02,  1.4710e-01,\n",
      "         -8.7791e-02,  1.3928e-01,  2.6531e-01, -1.0831e-01,  1.5120e-01,\n",
      "         -8.5177e-02, -3.5611e-02, -2.2652e-02,  1.7526e-01,  1.1004e-01],\n",
      "        [-5.0939e-02, -3.4662e-02, -2.7574e-02,  8.5381e-02, -2.5866e-01,\n",
      "         -1.5767e-01, -5.8148e-03, -1.1603e-01, -1.0701e-01,  5.4091e-02,\n",
      "         -1.1348e-01,  5.6931e-02,  1.9309e-01, -5.5475e-02,  4.5996e-02,\n",
      "         -1.2040e-01, -2.4866e-02,  1.5775e-01,  1.3858e-01,  2.4521e-01],\n",
      "        [ 5.5957e-02, -1.0722e-01, -6.6685e-02, -1.9394e-02, -3.1282e-01,\n",
      "         -1.1392e-01,  1.3424e-02, -3.9211e-02, -2.9714e-02,  1.3290e-01,\n",
      "         -8.6865e-02,  1.9106e-01,  2.4025e-01, -1.0052e-01,  7.5431e-02,\n",
      "         -1.3383e-02,  2.5907e-03, -3.2359e-02,  4.8970e-02,  1.4041e-01],\n",
      "        [ 3.6822e-02, -8.9833e-02, -2.3175e-02, -5.0834e-02, -1.5374e-01,\n",
      "         -3.0532e-02, -7.5928e-02, -6.1663e-02,  3.5450e-02,  1.8863e-01,\n",
      "         -1.2446e-01,  1.3730e-01,  2.2287e-01, -8.8562e-02,  3.6994e-02,\n",
      "          1.6468e-02, -1.7265e-02, -3.7416e-02,  4.8151e-02,  8.9200e-02],\n",
      "        [ 2.4524e-02, -2.4024e-02, -8.8506e-04,  6.7440e-02, -4.7256e-01,\n",
      "         -7.9833e-02,  2.5124e-02,  2.5183e-02, -7.8189e-03,  1.0979e-01,\n",
      "         -3.2361e-02,  1.9099e-01,  2.4612e-01, -6.2022e-02,  7.3083e-02,\n",
      "         -3.5777e-02, -5.3573e-03,  5.6199e-03,  6.9980e-02,  2.3413e-01],\n",
      "        [ 5.8755e-02, -1.4663e-01, -1.0869e-01, -1.0795e-01, -2.7223e-01,\n",
      "         -2.5548e-03, -2.6947e-02, -9.7021e-02, -1.2839e-02,  3.6347e-02,\n",
      "          7.9619e-02,  1.3421e-01,  1.7401e-01, -2.7514e-02,  1.8614e-01,\n",
      "         -5.3586e-02,  1.1056e-01, -7.0360e-02,  4.5953e-03,  1.4057e-01],\n",
      "        [ 1.5238e-04, -3.9331e-02, -1.6456e-02,  8.8874e-02, -2.7885e-01,\n",
      "         -1.0001e-01,  4.1762e-02, -6.8293e-03,  1.8616e-03,  1.1933e-01,\n",
      "         -5.3432e-03,  2.7507e-01,  1.9745e-01, -1.7857e-01,  8.4774e-02,\n",
      "          5.4389e-02, -2.0941e-02,  1.5141e-02,  1.1325e-01,  1.8077e-01],\n",
      "        [ 8.1986e-02, -1.1730e-01,  4.9363e-03,  4.9858e-02, -2.9357e-01,\n",
      "         -6.3150e-02,  2.6905e-02, -1.1937e-01, -2.9080e-02,  1.5919e-01,\n",
      "         -5.8410e-02,  1.6407e-01,  2.2554e-01, -1.0830e-01,  1.0092e-01,\n",
      "          2.1422e-02,  4.7803e-02, -2.6972e-02,  1.8116e-01,  1.9051e-01],\n",
      "        [ 1.1222e-01, -9.4495e-02, -1.1927e-01,  4.8369e-02, -1.7603e-01,\n",
      "          1.5983e-02,  6.4625e-04, -5.0384e-02, -2.0194e-02,  1.3175e-01,\n",
      "         -9.8681e-03,  1.3219e-01,  2.3689e-01, -1.2491e-01,  1.4399e-02,\n",
      "         -6.1958e-02,  3.9706e-02, -8.9457e-02,  5.8141e-02,  7.7774e-02],\n",
      "        [ 1.3022e-01, -4.9181e-02,  9.0395e-03, -1.9162e-02, -2.7193e-01,\n",
      "         -1.0806e-01, -4.6258e-03, -1.0419e-01,  2.9053e-02,  1.3466e-01,\n",
      "         -4.4668e-02,  1.0020e-01,  2.7840e-01, -2.9042e-02,  9.0902e-02,\n",
      "          2.1071e-03, -8.5483e-02, -3.8641e-02,  6.0105e-02,  1.8561e-01],\n",
      "        [ 3.2848e-02, -2.3484e-02, -1.1233e-01, -9.9980e-02, -1.5701e-01,\n",
      "         -1.5323e-01, -8.2581e-03, -6.6267e-03, -1.0926e-01, -5.5408e-02,\n",
      "          1.8179e-02,  8.1962e-02,  6.5117e-02, -1.1803e-01,  1.4514e-01,\n",
      "         -1.2842e-01,  3.3416e-02,  7.4808e-02,  9.2856e-02,  1.2752e-01],\n",
      "        [ 5.7443e-02,  1.0087e-02, -8.7685e-02,  7.6359e-02, -3.2396e-01,\n",
      "         -6.8947e-02, -1.7091e-02, -1.2193e-01,  9.8866e-02,  8.7375e-02,\n",
      "         -1.1627e-02,  1.4832e-01,  2.5597e-01, -1.3117e-01,  8.5846e-02,\n",
      "         -3.0676e-03, -3.9396e-02, -1.2247e-01,  2.4406e-01,  1.5906e-01]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([16,  2,  3, 17, 13, 16, 13, 16, 13, 18, 15, 13,  0,  0,  8,  3, 12,  8,\n",
      "        18, 10,  3,  6,  1,  2,  6,  9,  1,  1, 15,  9, 19, 19])\n",
      "tensor([[ 2.6939e-02, -6.5330e-02, -9.1621e-02,  6.2188e-03, -3.5200e-01,\n",
      "         -9.0038e-02,  8.7413e-02,  1.4650e-02,  9.1022e-03,  1.0378e-01,\n",
      "          6.9561e-02,  1.3290e-01,  1.3315e-01, -8.7661e-02,  9.9798e-02,\n",
      "         -9.1621e-02, -2.1896e-02, -8.1698e-02,  1.5835e-01,  2.4332e-01],\n",
      "        [ 4.0885e-02, -7.3871e-02,  4.3675e-02,  1.2904e-01, -3.8850e-01,\n",
      "         -9.0506e-02, -6.9825e-02, -8.3372e-02,  6.4450e-02,  9.0729e-02,\n",
      "         -6.5097e-02,  2.5595e-01,  2.2652e-01, -1.0248e-01,  1.7520e-02,\n",
      "         -3.8984e-02,  4.9801e-02, -6.0907e-02,  2.0480e-01,  3.0114e-01],\n",
      "        [ 6.4399e-02, -2.8633e-02, -9.2315e-02, -4.2564e-02, -2.3120e-01,\n",
      "         -5.3360e-02, -8.0748e-02, -8.4009e-02,  9.2415e-03,  1.5275e-01,\n",
      "          2.9220e-02,  7.4416e-02,  3.5774e-01, -3.7759e-02,  9.5810e-02,\n",
      "          5.1751e-02, -3.0951e-04, -1.2325e-01,  1.3453e-01,  1.9007e-01],\n",
      "        [ 1.3143e-01, -1.0451e-01, -5.2787e-02,  5.5100e-02, -2.9163e-01,\n",
      "         -1.3913e-01, -1.8151e-02, -9.3725e-02,  3.9966e-03,  1.2367e-01,\n",
      "          5.7951e-03,  1.7284e-01,  2.0073e-01, -1.9182e-02,  1.3951e-01,\n",
      "          1.3155e-02,  8.3975e-03, -6.1060e-02,  7.8010e-02,  1.9108e-01],\n",
      "        [ 8.5071e-02, -2.9494e-02, -5.2166e-02,  1.2014e-01, -3.1288e-01,\n",
      "         -3.0934e-02, -7.6602e-02, -1.0030e-01,  6.2039e-02,  1.7956e-01,\n",
      "         -9.0851e-03,  1.4409e-01,  3.1637e-01, -7.9632e-02,  2.2753e-01,\n",
      "         -2.9860e-02, -4.5766e-02,  7.8562e-03,  2.4859e-01,  2.1442e-01],\n",
      "        [-6.4437e-03, -1.4226e-01,  1.2407e-02, -4.7812e-03, -1.7752e-01,\n",
      "         -1.9803e-02, -3.6082e-03, -5.8825e-02,  8.8724e-04,  8.0492e-02,\n",
      "         -5.4370e-02,  1.2490e-01,  1.8190e-01, -9.1288e-02,  1.4336e-01,\n",
      "         -6.1265e-03,  2.8779e-02, -4.0026e-02,  1.0604e-01,  1.5117e-01],\n",
      "        [-3.8655e-03, -1.0000e-01, -3.3685e-02,  2.6951e-02, -2.3764e-01,\n",
      "         -6.0490e-02, -2.1949e-02, -3.0887e-02,  2.1817e-02,  1.8460e-01,\n",
      "         -1.5783e-02,  1.2706e-01,  2.4885e-01, -8.7418e-02,  1.3053e-01,\n",
      "          1.2638e-02, -3.4027e-02, -6.3452e-02,  8.6065e-02,  6.1949e-02],\n",
      "        [ 5.1519e-02,  1.8405e-03, -2.4331e-02,  1.2745e-01, -2.5914e-01,\n",
      "         -1.5231e-01,  8.3243e-03, -1.0660e-01,  3.6289e-02,  8.6641e-02,\n",
      "         -1.1237e-02,  1.1067e-01,  1.5571e-01, -5.2443e-02,  1.0673e-01,\n",
      "         -5.4915e-02, -1.0311e-01, -3.4583e-03,  8.6009e-02,  1.9681e-01],\n",
      "        [ 4.3083e-02, -1.5985e-02, -7.2735e-02,  8.3502e-02, -3.0226e-01,\n",
      "         -8.5319e-02, -5.1616e-02, -9.6456e-02,  7.0825e-02,  1.8717e-01,\n",
      "          1.1498e-03,  1.6656e-01,  2.4953e-01, -1.3697e-01,  1.3213e-01,\n",
      "          1.0361e-01, -1.9931e-02, -1.3069e-01,  1.4132e-01,  8.1973e-02],\n",
      "        [ 1.0319e-01, -9.6040e-02, -1.0071e-01,  4.4909e-02, -1.6441e-01,\n",
      "         -1.5530e-02, -1.1709e-02, -1.5198e-01, -6.8903e-02,  1.3955e-01,\n",
      "          6.1625e-02,  1.1218e-01,  1.8302e-01, -5.6661e-02,  9.5288e-02,\n",
      "         -5.5396e-02, -9.2856e-03, -4.5825e-03,  1.0205e-01,  8.5983e-02],\n",
      "        [ 1.1964e-01, -8.1210e-02, -7.4007e-02,  7.2789e-04, -2.9726e-01,\n",
      "         -6.5532e-02,  9.4551e-03, -1.0265e-01, -6.5384e-02,  1.3617e-01,\n",
      "          8.5727e-03,  1.5417e-01,  2.8407e-01, -1.3238e-01,  7.3872e-02,\n",
      "          4.3058e-02, -5.7773e-02, -1.5344e-01,  1.1233e-01,  1.8177e-01],\n",
      "        [ 1.2957e-01, -1.2962e-01, -1.1411e-01, -2.8910e-02, -2.3985e-01,\n",
      "         -1.1931e-01,  1.3834e-02, -1.0654e-01,  9.2693e-02,  1.4967e-01,\n",
      "         -2.6115e-02,  1.1150e-01,  2.4034e-01, -1.2492e-01,  1.2299e-01,\n",
      "         -4.8398e-03,  5.8024e-02, -6.3603e-02,  1.3553e-01,  1.6282e-01],\n",
      "        [ 5.4990e-02, -7.9857e-02, -5.6480e-02, -3.2592e-02, -1.1929e-01,\n",
      "         -1.3784e-01,  2.8367e-02, -1.6799e-01,  1.2650e-01,  1.5866e-01,\n",
      "         -6.3137e-02,  1.2396e-01,  1.7732e-01, -1.1561e-01,  1.6638e-01,\n",
      "         -8.3823e-02, -6.6867e-02,  5.1119e-03,  7.7909e-02,  1.7657e-02],\n",
      "        [-2.6832e-02, -4.3518e-02,  4.3806e-03,  6.3116e-02, -2.6153e-01,\n",
      "         -8.4459e-02, -3.1963e-02, -1.0223e-01,  6.9549e-03,  1.8197e-01,\n",
      "         -2.0261e-02,  1.9085e-01,  2.6143e-01, -9.8994e-02,  1.3183e-01,\n",
      "         -4.5399e-02,  2.9598e-02,  1.3146e-02,  1.9485e-01,  2.1009e-01],\n",
      "        [ 1.2087e-01, -3.4039e-02, -5.5037e-02,  6.3976e-03, -2.2791e-01,\n",
      "         -2.4787e-02,  2.2912e-02, -1.3823e-01, -3.8227e-02,  9.6844e-02,\n",
      "          5.4251e-02,  1.3170e-01,  3.1371e-01, -8.2226e-02,  1.1989e-01,\n",
      "          3.6375e-02, -3.2797e-04, -8.2646e-02,  1.9151e-02,  8.5213e-02],\n",
      "        [ 4.5012e-02, -1.4807e-03, -4.5015e-02, -1.5631e-02, -2.5897e-01,\n",
      "         -8.6708e-02,  3.4038e-02, -8.3583e-02,  3.9128e-03,  1.7654e-01,\n",
      "         -3.8773e-02,  1.4205e-01,  3.2668e-01, -1.0450e-01,  8.7191e-02,\n",
      "          2.8785e-02, -9.7468e-03,  1.6531e-03,  1.5180e-01,  1.5232e-01],\n",
      "        [-1.6905e-02, -2.3998e-02,  1.9652e-02,  6.3854e-03, -3.1263e-01,\n",
      "         -1.0555e-01, -6.7896e-03, -1.1272e-03, -6.3572e-02,  1.9214e-01,\n",
      "         -9.9814e-02,  1.7664e-01,  1.9865e-02, -1.0642e-01,  1.1397e-01,\n",
      "          9.6438e-03, -8.6347e-02,  4.0902e-02,  1.5673e-01,  2.4225e-01],\n",
      "        [ 4.1021e-02, -1.5611e-01,  5.8298e-02,  1.6718e-02, -2.3552e-01,\n",
      "         -4.1161e-02, -4.2629e-04, -9.0171e-02, -1.4766e-01,  1.8304e-01,\n",
      "         -3.7050e-02,  2.2768e-02,  3.1833e-01, -4.3816e-02, -4.2389e-03,\n",
      "         -7.1234e-03, -4.1868e-02, -1.6169e-01,  3.3190e-02,  1.3803e-01],\n",
      "        [ 7.0335e-02, -1.4032e-01, -7.4752e-02, -1.2473e-02, -1.6260e-01,\n",
      "         -6.9411e-02,  8.2629e-04, -1.2897e-01,  5.6334e-02,  1.1208e-01,\n",
      "         -1.4440e-04,  9.8998e-02,  2.3065e-01, -2.1882e-02,  9.5085e-02,\n",
      "          9.4457e-03,  5.4364e-02,  3.6961e-02,  1.3535e-01,  9.9941e-02],\n",
      "        [ 2.1052e-02, -9.8371e-02,  2.8517e-02, -2.1542e-02, -2.7601e-01,\n",
      "         -1.1797e-01,  2.3203e-03,  1.3671e-02, -3.5552e-03,  1.5683e-01,\n",
      "          1.3254e-03,  1.6409e-01,  2.5311e-01, -8.1391e-02,  1.4467e-01,\n",
      "         -1.7162e-02,  5.9751e-02,  3.2279e-02,  7.6979e-02,  1.9774e-01],\n",
      "        [ 1.0095e-01, -1.1811e-01,  3.6070e-02,  1.2106e-01, -5.9537e-01,\n",
      "         -3.5995e-02, -7.1604e-02, -1.6662e-01, -8.2094e-02,  2.0905e-01,\n",
      "         -1.5242e-02,  2.2445e-01,  2.1559e-01,  1.2788e-01,  4.2302e-02,\n",
      "         -2.0765e-02, -7.0716e-02,  7.8677e-02,  1.4525e-01,  4.5291e-01],\n",
      "        [ 7.2185e-02, -5.8047e-02, -1.8016e-01, -9.1972e-02, -5.3955e-02,\n",
      "         -1.5691e-01,  3.9391e-02, -6.8395e-02, -4.1517e-02,  1.5297e-01,\n",
      "          4.8792e-05,  1.6233e-02,  1.7502e-01, -2.4196e-02,  1.2656e-01,\n",
      "          4.4803e-02,  1.2872e-01, -8.6973e-02, -1.1034e-02, -6.6159e-02],\n",
      "        [ 4.6344e-03, -8.4875e-02, -7.5115e-02,  1.6778e-01, -3.4150e-01,\n",
      "         -1.1929e-01, -6.3500e-02, -5.1987e-02, -2.7254e-03,  1.5414e-01,\n",
      "         -5.4639e-02,  2.9437e-01,  2.3498e-01, -5.2691e-02, -2.6276e-02,\n",
      "         -5.0936e-02,  4.0953e-02,  1.1289e-02,  1.6803e-01,  2.6257e-01],\n",
      "        [ 2.5162e-02,  3.2688e-02, -4.4706e-02,  8.9847e-02, -3.1477e-01,\n",
      "         -9.6670e-02, -2.8317e-02, -5.0640e-02, -2.3267e-02,  1.5456e-01,\n",
      "          1.9699e-02,  1.8116e-01,  2.4434e-01, -6.2728e-02,  6.8774e-02,\n",
      "         -3.2422e-02, -3.5900e-02, -1.3465e-03,  1.4360e-01,  1.9535e-01],\n",
      "        [ 7.8551e-02, -9.3726e-02, -1.1301e-01, -4.1116e-02, -3.1144e-01,\n",
      "         -1.1156e-01,  6.5158e-02, -7.7793e-02,  2.9011e-02,  2.4025e-02,\n",
      "         -1.7638e-02,  1.1080e-01,  1.8980e-01, -1.4112e-01,  1.0891e-01,\n",
      "         -2.4781e-02,  1.2034e-02, -3.4370e-02,  9.8644e-02,  1.6322e-01],\n",
      "        [ 1.2784e-02, -5.3703e-02, -2.5975e-02,  5.5660e-03, -2.0528e-01,\n",
      "         -1.3041e-01, -6.1293e-02,  2.4275e-02,  3.8160e-02,  1.3154e-01,\n",
      "         -9.8291e-02,  6.0709e-02,  2.2517e-01, -7.5971e-02,  7.8746e-02,\n",
      "          4.6056e-02, -3.8997e-02, -8.4355e-02,  3.1705e-02,  9.1666e-02],\n",
      "        [ 1.6309e-02, -6.3854e-02,  9.3698e-02,  7.7795e-02, -4.8902e-01,\n",
      "         -2.9087e-02, -2.2866e-02, -9.7382e-02,  4.2438e-02,  2.0310e-01,\n",
      "         -3.6208e-02,  3.1211e-01,  3.2938e-01, -4.0582e-02,  2.0068e-01,\n",
      "          2.8368e-02, -5.6756e-02,  3.2465e-02,  1.9685e-01,  3.5876e-01],\n",
      "        [-9.3029e-03, -7.8233e-02, -3.3268e-02, -3.5238e-02, -2.7122e-01,\n",
      "         -5.2245e-02,  1.5119e-02, -2.2580e-02,  7.8230e-02,  6.9158e-02,\n",
      "          4.8375e-02,  1.4772e-01,  1.9816e-01, -4.5857e-02,  1.4219e-01,\n",
      "         -2.2781e-02,  5.2244e-02,  1.5677e-02,  9.8423e-02,  1.9320e-01],\n",
      "        [-1.3606e-02, -7.7596e-02, -1.0678e-01, -1.1847e-02, -1.3117e-01,\n",
      "         -1.4443e-01, -6.5587e-02, -1.1184e-02,  5.8060e-02,  6.7759e-02,\n",
      "         -9.5410e-02,  1.2931e-01,  3.1986e-01, -8.9914e-02,  9.4036e-02,\n",
      "          3.7817e-02,  2.9753e-02,  1.7127e-03,  5.0042e-02,  2.4511e-02],\n",
      "        [ 5.9032e-02, -5.7883e-02, -7.5680e-02,  9.5315e-02, -2.5465e-01,\n",
      "         -5.4067e-02, -8.7519e-03,  1.7636e-02,  8.6875e-02,  1.1854e-01,\n",
      "         -3.9443e-02,  1.6497e-01,  1.7254e-01, -3.3164e-02,  9.5298e-02,\n",
      "         -5.3083e-02,  1.3107e-02, -4.5211e-02,  6.2800e-02,  1.1238e-01],\n",
      "        [ 1.0938e-01, -4.7884e-02, -9.7995e-03, -7.6986e-02, -1.6699e-01,\n",
      "         -2.2685e-02,  6.1686e-02, -7.6307e-02, -5.9945e-02,  5.8857e-02,\n",
      "          3.5435e-02,  7.1068e-02,  1.4151e-01, -9.1242e-02,  1.2956e-01,\n",
      "          4.4551e-02,  2.2183e-02, -9.7183e-02, -5.0829e-02,  7.9045e-02],\n",
      "        [ 4.5488e-02, -5.8773e-02, -7.5130e-02, -8.1371e-02, -2.5095e-01,\n",
      "         -1.2178e-01,  1.4657e-02, -3.5768e-02,  1.2344e-01,  1.6281e-01,\n",
      "          3.4690e-02,  1.4894e-01,  1.9950e-01,  7.3262e-04,  2.1293e-02,\n",
      "          5.8550e-02, -6.4184e-02, -7.4275e-02,  5.5390e-03,  1.2140e-01]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([11,  9, 16, 13, 18, 11, 16,  3, 17, 16,  5,  7,  1,  2,  8,  8,  1,  7,\n",
      "        13,  9, 18, 13,  8, 18,  0, 10,  8, 17, 18, 15,  8,  2])\n",
      "tensor([[-2.5003e-02, -5.3456e-02, -1.0133e-01, -8.0906e-02, -1.0862e-01,\n",
      "         -1.1254e-01,  5.1702e-02, -1.1478e-01,  1.1481e-01,  1.3148e-01,\n",
      "         -5.6500e-02,  6.3032e-02,  2.0978e-01, -1.6199e-01,  4.6745e-02,\n",
      "          9.1873e-02, -2.4545e-02, -7.9809e-02,  4.7691e-02,  4.2385e-02],\n",
      "        [ 1.0948e-01, -2.9041e-02, -4.6256e-02, -9.7764e-02, -3.0427e-01,\n",
      "         -1.6661e-01,  1.0026e-02, -6.7042e-02,  4.0618e-02,  6.3625e-02,\n",
      "          6.1569e-02,  1.5561e-01,  1.6491e-01, -4.9941e-02,  1.0474e-01,\n",
      "         -8.3575e-03, -3.3376e-02,  3.4837e-02,  5.6416e-02,  1.6081e-01],\n",
      "        [ 7.2401e-03, -3.4632e-02, -7.1707e-02,  1.3739e-02, -2.4753e-01,\n",
      "         -1.2333e-01,  7.5304e-02,  8.5657e-03, -2.9347e-02,  1.3676e-01,\n",
      "          2.3306e-02,  1.0501e-01,  1.6324e-01, -1.5421e-01,  9.1579e-02,\n",
      "         -4.7229e-04,  3.5212e-02, -2.7861e-02,  1.3246e-01,  1.6988e-01],\n",
      "        [ 1.4099e-01, -2.0977e-01, -6.6499e-03, -1.9490e-01, -2.1085e-01,\n",
      "         -2.1800e-02,  3.4373e-02, -1.5537e-01,  7.3587e-02,  1.4244e-01,\n",
      "          9.9916e-02,  1.4939e-01,  2.3425e-01, -3.5527e-02,  6.6672e-02,\n",
      "          8.2127e-02,  6.1131e-02,  5.8302e-04,  4.8615e-02,  6.9632e-03],\n",
      "        [ 7.5047e-02, -1.0980e-01, -7.1006e-02, -1.0560e-02, -2.5686e-01,\n",
      "         -1.3800e-01,  3.4421e-02, -5.6280e-02,  5.1209e-03,  1.2156e-01,\n",
      "         -1.4078e-02,  2.4581e-01,  2.6961e-01, -7.6029e-02,  8.7738e-02,\n",
      "          6.8071e-03,  6.1411e-02,  6.5420e-02,  1.2624e-01,  1.0808e-01],\n",
      "        [ 2.0266e-02, -8.1486e-02, -5.4593e-02,  1.8852e-02, -2.2778e-01,\n",
      "         -1.0338e-01,  5.7117e-02, -7.7049e-02,  1.9725e-02,  1.1957e-01,\n",
      "         -6.1425e-02,  1.1936e-01,  2.9141e-01, -1.2705e-01,  9.3286e-02,\n",
      "          2.9493e-02,  7.9874e-02, -5.5965e-02,  1.3204e-01,  1.3097e-01],\n",
      "        [ 8.9657e-02, -7.8505e-02, -1.5592e-01,  5.8483e-02, -2.4171e-01,\n",
      "         -5.6488e-02, -2.6771e-02, -9.5126e-02,  9.2526e-02,  1.5887e-01,\n",
      "         -4.4325e-02,  1.7973e-01,  2.3531e-01, -6.2436e-02,  9.0581e-02,\n",
      "          2.6430e-02,  5.1762e-02,  7.2752e-02,  6.7070e-02,  1.3017e-01],\n",
      "        [-3.0070e-02, -4.2979e-02, -8.6000e-02, -4.3588e-02, -2.7257e-01,\n",
      "         -1.2064e-01,  8.4773e-03, -5.5194e-02, -1.8242e-02,  5.4559e-02,\n",
      "          4.7766e-02,  9.2758e-02,  1.2222e-01, -7.0722e-02,  5.7516e-02,\n",
      "         -2.1184e-02, -3.2093e-02, -3.3853e-02,  7.7628e-02,  1.3643e-01],\n",
      "        [-4.3882e-02,  5.8166e-02,  7.0685e-02, -1.4280e-02, -2.2405e-01,\n",
      "         -1.1535e-01, -4.1982e-02,  1.1752e-01,  5.7870e-02,  6.3779e-02,\n",
      "         -1.5025e-01,  2.7594e-01,  1.0387e-01, -1.2820e-01,  4.9631e-04,\n",
      "         -7.2357e-02, -5.3019e-02,  1.0397e-01,  6.2349e-02,  9.2003e-03],\n",
      "        [ 4.7068e-02, -4.1972e-02, -1.0590e-02, -5.0731e-02, -2.8928e-01,\n",
      "         -6.4894e-02, -7.4479e-02, -1.1242e-01, -1.5095e-01,  1.5085e-01,\n",
      "          4.1618e-03,  1.5173e-01,  3.1252e-01, -3.8813e-02,  1.5509e-01,\n",
      "          1.5807e-02,  9.3856e-03, -5.4056e-03,  1.2311e-01,  1.2212e-01],\n",
      "        [ 9.4559e-02,  2.8801e-02, -5.4793e-02,  1.4017e-02, -2.4903e-01,\n",
      "         -1.6590e-01,  9.1669e-04,  1.7388e-02,  1.0045e-01,  1.1856e-01,\n",
      "         -6.6484e-02,  1.6764e-01,  2.3106e-01, -6.1575e-02,  3.1225e-02,\n",
      "         -7.3529e-02, -4.5251e-02, -7.1476e-02,  2.0279e-01,  6.0534e-02],\n",
      "        [-1.8843e-02, -3.9206e-02, -1.9150e-01, -5.3729e-02, -2.6191e-01,\n",
      "         -1.0838e-01, -3.9155e-02, -2.9559e-02,  1.0585e-01,  1.1146e-01,\n",
      "         -1.6094e-03,  1.5190e-01,  2.7634e-01, -7.6344e-02,  5.9760e-02,\n",
      "          5.6671e-02,  4.8287e-02, -1.3945e-02, -6.8380e-03,  3.5370e-02],\n",
      "        [ 3.8597e-02, -5.9096e-02, -2.1265e-02,  7.5397e-02, -2.2050e-01,\n",
      "         -4.7736e-02, -2.4394e-02, -2.2351e-02, -3.5513e-02,  1.3122e-01,\n",
      "         -4.2239e-02,  1.5552e-01,  2.3453e-01, -1.2394e-01,  1.7999e-01,\n",
      "         -1.3025e-02,  1.3154e-02, -8.5749e-02,  6.5857e-02,  1.4429e-01],\n",
      "        [ 8.7668e-02, -1.0578e-03,  2.6394e-02,  1.3172e-01, -3.6645e-01,\n",
      "          1.8616e-03,  1.4914e-02, -6.9962e-02, -8.0344e-02,  2.4343e-01,\n",
      "          4.1982e-02,  2.2222e-01,  3.1970e-01, -1.7465e-01,  1.1644e-01,\n",
      "         -2.0234e-02,  3.4302e-02, -2.4184e-02,  2.9369e-01,  2.3020e-01],\n",
      "        [ 6.5463e-02, -6.6879e-02, -5.4407e-02, -7.2558e-03, -3.5582e-01,\n",
      "         -3.5618e-02, -1.0054e-01, -7.7680e-02, -2.8520e-03, -1.7589e-02,\n",
      "         -9.5867e-02,  1.3999e-01,  3.0244e-01, -2.9914e-02,  7.0730e-02,\n",
      "          6.7275e-02, -2.4917e-02, -1.2457e-01,  2.4623e-02,  1.0180e-01],\n",
      "        [ 1.2611e-01, -2.5067e-02, -1.5220e-01, -6.0850e-04, -2.1847e-01,\n",
      "         -7.6463e-02, -1.0101e-01, -9.7407e-03,  4.2494e-02,  9.3916e-02,\n",
      "         -5.0683e-02,  4.3427e-02,  2.8806e-01, -4.4342e-02,  8.2933e-02,\n",
      "          4.0845e-02,  3.7672e-02, -1.3195e-01,  7.6078e-03,  6.4047e-02],\n",
      "        [ 9.1807e-02, -7.5408e-02, -4.5488e-02,  4.6006e-02, -2.5613e-01,\n",
      "         -7.4233e-02, -1.0687e-01, -7.3639e-02,  5.9667e-02,  2.3513e-01,\n",
      "         -2.0115e-03,  1.4069e-01,  2.9523e-01, -8.9119e-02,  1.3482e-01,\n",
      "         -5.2258e-02, -1.7808e-02, -1.1378e-02,  1.5617e-01,  1.2356e-01],\n",
      "        [-2.4367e-02, -6.9701e-02, -7.2863e-02, -1.2661e-01, -2.0936e-01,\n",
      "         -1.0294e-01,  1.4615e-02, -8.1370e-02, -3.6471e-02,  1.6476e-01,\n",
      "          4.0712e-02,  1.1277e-01,  2.0360e-01, -7.2621e-02,  9.4962e-02,\n",
      "          7.8477e-02,  6.0613e-02, -2.7767e-02,  1.0142e-01,  1.0250e-01],\n",
      "        [ 4.7754e-02, -1.0057e-01, -1.4525e-01, -5.2221e-05, -2.5691e-01,\n",
      "         -2.8568e-02, -2.4476e-02, -4.5699e-02,  7.1604e-02,  1.3716e-01,\n",
      "         -3.2960e-03,  9.9961e-02,  2.1655e-01, -1.1107e-01,  4.9684e-02,\n",
      "          4.9177e-02,  3.9092e-02, -1.2958e-01,  5.3301e-02,  1.6943e-01],\n",
      "        [ 5.6692e-03, -3.7108e-02, -7.9609e-03, -6.0575e-02, -2.6221e-01,\n",
      "         -1.9055e-02,  1.1490e-02, -2.7330e-02,  8.1989e-02,  1.0995e-01,\n",
      "         -2.6054e-02,  2.2435e-01,  2.4663e-01, -2.0235e-01,  9.5509e-02,\n",
      "          8.1164e-02,  1.1222e-01, -4.4215e-02,  3.6120e-02,  8.8889e-02],\n",
      "        [-2.1507e-02, -1.4931e-02, -5.7186e-03,  3.8011e-02, -4.3099e-01,\n",
      "         -3.3306e-02, -2.2934e-02, -5.9220e-02,  1.8403e-02,  1.4685e-01,\n",
      "         -4.0373e-02,  2.2941e-01,  2.1802e-01, -9.5706e-02,  1.2804e-01,\n",
      "          6.3379e-02,  1.7021e-02, -6.1669e-02,  2.0182e-01,  2.4445e-01],\n",
      "        [ 3.0011e-02, -1.1838e-01, -8.0708e-02, -5.4386e-02, -2.6765e-01,\n",
      "          1.2470e-02,  5.4901e-02, -8.1654e-02,  3.2579e-02,  1.2553e-02,\n",
      "         -2.5234e-02,  7.9685e-02,  1.4986e-01, -1.8362e-01,  1.2575e-01,\n",
      "          5.6896e-02,  9.1397e-02, -1.2388e-01,  4.4995e-02,  1.1748e-01],\n",
      "        [ 4.0218e-02, -3.8904e-02,  1.3531e-02,  6.5627e-02, -2.5669e-01,\n",
      "         -7.0861e-02,  3.9473e-02, -1.4173e-01,  1.9338e-02,  8.5728e-02,\n",
      "          4.0431e-02,  1.2653e-01,  1.5866e-01, -1.3420e-01,  1.5781e-01,\n",
      "         -2.4726e-02, -1.9832e-02, -4.2933e-02,  1.8914e-01,  1.4964e-01],\n",
      "        [ 9.8410e-02, -4.1355e-02,  5.4951e-02,  7.1300e-02, -4.7316e-01,\n",
      "         -1.2769e-01, -4.4055e-02, -1.1973e-02, -8.6393e-02,  1.6071e-01,\n",
      "         -8.6122e-02,  2.2862e-01,  2.7219e-01,  4.3344e-03,  1.4976e-01,\n",
      "         -7.2382e-03, -3.3760e-02,  5.1391e-02,  1.2928e-01,  2.9969e-01],\n",
      "        [ 8.4644e-02, -7.5222e-02, -1.2053e-01, -8.2466e-03, -1.7869e-01,\n",
      "         -6.5538e-02,  3.8021e-02, -3.2992e-02, -6.0063e-02,  1.4530e-01,\n",
      "         -5.3087e-02,  8.0164e-02,  2.0748e-01, -5.8639e-02,  5.2285e-02,\n",
      "          3.6132e-03,  7.2954e-03, -7.8795e-02,  8.3172e-02,  7.9470e-02],\n",
      "        [ 5.4112e-02, -1.1712e-01, -6.5260e-02, -2.5794e-02, -3.2845e-01,\n",
      "         -1.3346e-01,  4.2259e-03, -1.1855e-01,  4.7770e-02,  4.9280e-02,\n",
      "         -7.2117e-02,  2.0758e-01,  2.3600e-01, -1.1706e-01,  3.5096e-02,\n",
      "          7.6228e-02,  1.3814e-01, -6.3511e-02,  1.2488e-01,  1.4502e-01],\n",
      "        [ 5.4064e-02, -5.1528e-02, -1.5291e-01,  3.4647e-02, -3.5195e-01,\n",
      "         -8.5646e-02,  1.2756e-02, -1.1584e-02,  8.1355e-03,  1.2164e-01,\n",
      "          4.0719e-02,  1.8085e-01,  2.5646e-01, -9.1615e-02,  1.1002e-01,\n",
      "         -3.7269e-02, -3.7399e-02, -5.2446e-02,  1.2863e-01,  1.9511e-01],\n",
      "        [ 2.0870e-02, -1.0964e-01, -1.7347e-01, -3.3047e-02, -1.8027e-01,\n",
      "         -1.0061e-01, -4.4108e-02, -4.2095e-02,  4.0053e-02,  9.1296e-02,\n",
      "         -4.9305e-03,  7.5309e-02,  2.5411e-01, -5.8857e-02,  2.9825e-02,\n",
      "          3.4168e-02,  1.3225e-02, -3.9481e-03,  1.0916e-02,  7.2876e-02],\n",
      "        [ 2.2602e-02,  4.1415e-02, -1.5637e-02,  5.0441e-02, -2.6623e-01,\n",
      "         -1.4297e-01,  1.3146e-01,  2.1798e-02,  5.6815e-02,  2.5249e-01,\n",
      "         -2.0432e-01,  1.2914e-01,  2.2481e-01, -5.8055e-02,  9.0569e-02,\n",
      "         -1.7958e-01, -2.0385e-01,  5.9309e-02,  2.3446e-01,  2.8018e-01],\n",
      "        [-1.3993e-03, -6.2166e-02,  9.5149e-02,  1.2330e-01, -4.1894e-01,\n",
      "         -1.0039e-01,  4.9696e-02, -7.3603e-02, -1.0800e-01,  1.9442e-01,\n",
      "         -3.4860e-03,  3.0872e-01,  2.5012e-01, -1.1594e-01,  2.3072e-02,\n",
      "         -6.5537e-02,  1.0361e-01,  8.2139e-02,  3.0971e-01,  3.5523e-01],\n",
      "        [ 3.7704e-02, -1.0579e-01,  1.9273e-02,  8.4922e-02, -3.0362e-01,\n",
      "         -9.6613e-02,  1.3360e-02, -8.6306e-02,  9.1957e-02,  1.4587e-01,\n",
      "         -4.7441e-03,  1.4743e-01,  2.0116e-01, -1.2049e-01,  1.1683e-01,\n",
      "          3.6176e-02, -5.7993e-03, -7.2317e-02,  9.5066e-02,  1.1429e-01],\n",
      "        [ 2.0945e-02, -3.4304e-02,  1.7852e-02,  8.9189e-02, -4.1346e-01,\n",
      "         -1.0956e-01, -1.5380e-02, -5.8254e-02,  3.0961e-02,  7.7024e-02,\n",
      "          3.9788e-02,  2.2372e-01,  1.8908e-01, -1.7089e-01,  1.1582e-01,\n",
      "          3.6397e-02,  6.8656e-02,  4.2193e-03,  1.3010e-01,  2.4632e-01]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([ 4, 18,  2, 18,  0, 15,  9, 14,  6,  7, 12, 10, 10, 18,  7, 12,  2, 16,\n",
      "        14,  4,  5,  4, 10,  1,  8, 15, 17, 16, 10,  5,  1,  2])\n",
      "tensor([[ 4.5325e-02, -1.6820e-01, -1.4617e-01,  4.8887e-02, -3.7885e-01,\n",
      "         -1.1486e-01, -1.5158e-01, -7.4897e-02, -1.7670e-01,  6.1253e-02,\n",
      "          1.9390e-02,  1.6329e-01,  3.1249e-01, -3.8032e-02,  6.5649e-02,\n",
      "          1.2491e-01,  1.1085e-01, -7.7748e-02,  7.3860e-02,  4.0840e-02],\n",
      "        [ 1.3301e-01, -8.0220e-02, -1.2693e-01, -4.3140e-02, -2.0619e-01,\n",
      "         -1.0251e-01,  2.0202e-02, -1.0131e-01,  1.5296e-02,  1.4429e-01,\n",
      "         -1.0788e-02,  1.5630e-01,  2.0016e-01, -6.4640e-02,  5.5840e-02,\n",
      "          9.8144e-03, -1.2521e-01, -4.0059e-02,  3.4792e-02,  1.6214e-01],\n",
      "        [ 1.4722e-01, -1.0563e-01, -5.6913e-02,  3.6775e-02, -3.1590e-01,\n",
      "         -7.5187e-02,  9.9062e-02, -1.0565e-01,  1.0687e-01,  1.7392e-01,\n",
      "          3.0049e-02,  1.6249e-01,  2.3754e-01, -1.3958e-01,  1.4225e-01,\n",
      "         -3.2798e-02, -7.3330e-03, -2.0492e-02,  8.7307e-02,  2.4124e-01],\n",
      "        [ 5.7891e-02, -6.3005e-02, -7.1603e-02, -3.4259e-02, -2.8425e-01,\n",
      "         -1.3779e-01,  7.1162e-02, -8.3997e-02, -2.2163e-02,  5.4602e-02,\n",
      "          8.0425e-03,  7.6766e-02,  1.7724e-01, -3.5867e-02,  6.5513e-02,\n",
      "          4.5414e-02, -2.8594e-03, -6.2776e-02,  9.9548e-02,  1.6631e-01],\n",
      "        [ 1.9010e-02, -4.6488e-02, -9.5017e-02, -4.9930e-02, -1.4955e-01,\n",
      "         -2.2007e-01,  3.4195e-02, -3.4961e-02, -7.3952e-02,  1.0659e-01,\n",
      "         -9.7508e-02,  1.1773e-01,  2.9873e-01, -1.4766e-01,  1.5712e-01,\n",
      "          4.5584e-02, -5.2469e-02, -1.0054e-02,  1.0391e-01,  1.1944e-01],\n",
      "        [ 5.1999e-02, -1.7105e-01, -1.3559e-01,  6.0784e-04, -2.1123e-01,\n",
      "         -3.9232e-02,  5.1030e-02, -9.0816e-02, -5.2921e-02,  1.0931e-01,\n",
      "          6.2300e-02,  3.5587e-02,  1.9020e-01, -4.3835e-02,  8.8359e-02,\n",
      "         -5.8542e-02,  5.5705e-02, -7.6079e-02,  9.9362e-03,  1.2426e-01],\n",
      "        [-1.4138e-01, -8.9557e-02,  2.8039e-02, -4.3818e-02, -3.2351e-01,\n",
      "         -6.2900e-02,  2.2226e-02,  5.7250e-02, -2.1008e-01,  1.3686e-01,\n",
      "         -4.3100e-02,  6.1386e-02,  1.8981e-01, -1.1239e-01,  8.0511e-02,\n",
      "         -1.0238e-02,  4.6121e-02,  3.9622e-02,  2.0541e-01,  1.6721e-01],\n",
      "        [ 4.8712e-02, -7.7589e-02,  1.3810e-02,  3.5842e-02, -2.5791e-01,\n",
      "         -1.2169e-01, -2.0894e-02, -1.2159e-01,  8.4943e-03,  1.1284e-01,\n",
      "          8.5296e-03,  1.1684e-01,  2.1477e-01, -6.4757e-02,  1.2286e-01,\n",
      "         -2.5610e-03,  9.8802e-02, -4.5855e-02,  3.7397e-02,  1.5210e-01],\n",
      "        [ 7.0790e-02, -5.2452e-02,  1.7010e-02,  5.3234e-02, -3.4176e-01,\n",
      "         -7.2337e-02,  8.9754e-03,  2.1064e-02,  1.0731e-02,  1.9806e-01,\n",
      "         -2.7474e-02,  1.9607e-01,  1.6716e-01, -9.2121e-02,  8.0701e-02,\n",
      "         -4.5778e-02,  4.4124e-02, -3.2378e-02,  1.2920e-01,  1.3363e-01],\n",
      "        [ 7.7647e-02, -5.6287e-02, -1.1118e-01,  5.8070e-02, -2.1130e-01,\n",
      "         -7.7007e-02, -5.0565e-02, -1.6023e-02, -6.9520e-02,  1.2883e-01,\n",
      "          5.5855e-04,  1.5484e-01,  1.8881e-01, -1.4796e-01,  1.0355e-01,\n",
      "          8.9903e-03,  1.8414e-02, -4.5231e-02,  2.1276e-01,  1.2045e-01],\n",
      "        [ 1.0818e-01, -7.0520e-02, -1.9083e-01,  9.7470e-03, -9.5947e-02,\n",
      "         -9.9290e-02,  1.6509e-02, -7.9398e-03,  6.5979e-02,  1.7387e-01,\n",
      "         -1.0797e-01,  1.3007e-01,  2.2946e-01, -6.3977e-02,  4.8642e-02,\n",
      "         -9.6769e-02, -7.9396e-02, -3.4786e-02,  2.9677e-02,  1.0755e-01],\n",
      "        [-4.5776e-02,  1.4757e-03, -8.6422e-02, -1.0871e-02, -1.8242e-01,\n",
      "         -1.3951e-01,  4.9988e-02, -8.5424e-02,  3.1162e-02,  1.2463e-01,\n",
      "          1.2449e-02,  8.0213e-02,  2.6088e-01, -4.5466e-03,  3.0402e-02,\n",
      "         -3.5341e-02, -1.1652e-02, -1.3546e-02,  5.0277e-02,  4.5392e-02],\n",
      "        [ 1.7843e-02, -3.2469e-02,  5.4608e-02,  8.2484e-02, -3.3640e-01,\n",
      "         -1.5573e-01,  1.7583e-02, -8.0124e-02,  5.7072e-02,  2.3769e-01,\n",
      "         -1.1271e-01,  1.8071e-01,  2.1350e-01, -4.9557e-02,  4.1722e-02,\n",
      "          2.0573e-02, -1.2285e-04,  2.4951e-02,  2.2174e-01,  2.3097e-01],\n",
      "        [ 2.6794e-02, -7.8149e-02, -3.4415e-02, -2.9361e-02, -2.4623e-01,\n",
      "         -8.2138e-02,  4.1239e-02, -5.7472e-02,  3.3433e-02,  1.1783e-01,\n",
      "         -3.0537e-02,  9.3663e-02,  1.7073e-01, -6.2621e-02,  4.7806e-02,\n",
      "         -4.7858e-02,  2.9641e-03, -4.8224e-02,  7.8126e-02,  1.7250e-01],\n",
      "        [ 9.8765e-03, -2.0325e-02,  1.0911e-01,  2.2864e-01, -6.0575e-01,\n",
      "         -1.8475e-02,  4.1340e-03, -4.3933e-02, -6.3515e-02,  8.5383e-02,\n",
      "         -1.2275e-01,  2.4536e-01,  2.5134e-01, -5.3770e-02,  9.1115e-02,\n",
      "         -3.2151e-02,  2.5148e-02, -1.1575e-01,  2.6168e-01,  3.3562e-01],\n",
      "        [ 7.8058e-02, -4.6331e-02, -1.3594e-01,  5.2265e-02, -2.7525e-01,\n",
      "         -1.3171e-01, -3.1886e-02, -1.0750e-01,  3.7391e-02,  1.3954e-01,\n",
      "         -9.6595e-02,  1.9223e-01,  1.9332e-01, -5.5944e-02,  9.4046e-02,\n",
      "         -3.4498e-02,  4.8683e-02, -2.5215e-02,  1.2999e-01,  2.0369e-01],\n",
      "        [ 4.6415e-02, -1.3126e-01, -2.0577e-02, -3.1545e-02, -2.3100e-01,\n",
      "         -9.1512e-02, -4.4422e-02, -7.1504e-02, -5.1616e-02,  1.2979e-01,\n",
      "         -4.1571e-02,  1.1894e-01,  2.1545e-01, -3.4185e-02,  7.5409e-02,\n",
      "          4.7082e-02,  1.3257e-03, -1.1479e-01,  6.4970e-02,  8.2041e-03],\n",
      "        [ 6.3788e-02, -7.9731e-02, -6.0812e-02,  3.4697e-02, -2.4685e-01,\n",
      "         -5.0506e-02,  4.1509e-02, -1.0081e-01,  7.2466e-02,  1.6936e-01,\n",
      "         -3.4696e-03,  9.6933e-02,  2.5442e-01, -9.5816e-02,  1.6056e-01,\n",
      "          1.5938e-02, -7.1565e-02, -4.6998e-02,  1.4360e-01,  1.4776e-01],\n",
      "        [ 1.1122e-03, -6.5351e-02, -1.1680e-01, -7.7490e-02, -1.9076e-01,\n",
      "         -9.2184e-02,  3.5999e-02, -1.8046e-02,  3.0558e-02,  1.3605e-01,\n",
      "         -6.5950e-02,  9.2153e-02,  2.4971e-01, -8.9610e-02,  4.2698e-02,\n",
      "         -7.1842e-04, -3.2118e-02, -5.4268e-02,  2.1098e-02,  1.4640e-01],\n",
      "        [ 1.1406e-01, -1.0852e-01, -3.2169e-02, -9.2079e-02, -2.4489e-01,\n",
      "         -3.0516e-02,  3.1695e-02,  2.8533e-02,  2.7705e-02,  1.0011e-02,\n",
      "         -5.3404e-02,  8.3778e-02,  2.2769e-01, -4.9009e-02,  9.3324e-02,\n",
      "         -1.8493e-02,  6.0442e-02, -2.0272e-02,  6.2495e-02,  1.5346e-01],\n",
      "        [-4.3727e-02, -7.0917e-02, -1.2062e-01, -6.1789e-02, -2.0141e-01,\n",
      "         -9.7492e-02,  5.4349e-02,  2.3305e-02,  5.8535e-02,  1.5735e-01,\n",
      "         -1.4449e-02,  2.0438e-01,  2.1915e-01, -1.2949e-01,  3.5200e-02,\n",
      "         -4.2360e-02,  4.8959e-02, -4.9829e-02,  4.2580e-02,  5.8805e-02],\n",
      "        [ 1.2301e-02, -1.5137e-01,  1.4541e-01,  1.8042e-01, -3.9971e-01,\n",
      "         -8.3704e-02, -1.5637e-02, -6.9442e-02, -6.5932e-03,  2.3016e-01,\n",
      "         -4.8298e-02,  2.9172e-01,  2.0377e-01, -1.7511e-01,  1.1041e-01,\n",
      "          1.5146e-02,  7.4712e-02, -2.0717e-02,  2.1405e-01,  1.8670e-01],\n",
      "        [-2.8513e-02, -7.6579e-02, -8.4761e-02,  2.5202e-02, -2.0685e-01,\n",
      "         -8.6440e-02, -4.3051e-02,  8.6943e-02,  1.1288e-01,  8.8197e-02,\n",
      "          1.8444e-02,  6.5329e-02,  1.4493e-01,  1.2813e-02,  1.5676e-01,\n",
      "         -8.4631e-02, -6.6717e-02,  1.9550e-02,  4.9114e-02,  3.2070e-02],\n",
      "        [-2.1687e-02, -6.7784e-02, -2.7840e-02, -5.2157e-02, -2.9677e-01,\n",
      "         -8.9991e-02, -4.9282e-03, -7.1999e-02, -7.9481e-02,  1.1785e-01,\n",
      "          5.4848e-02,  1.2231e-01,  2.4887e-01, -1.3808e-01,  1.9964e-01,\n",
      "          1.5627e-02,  2.8049e-02, -2.4192e-03,  1.4138e-01,  2.4928e-01],\n",
      "        [ 2.2705e-01,  5.3975e-02,  4.1923e-01,  7.4368e-01, -1.1123e+00,\n",
      "          3.2088e-02, -2.5617e-01, -2.8116e-01, -3.9025e-02,  2.8603e-01,\n",
      "         -9.4579e-03,  6.9802e-01,  4.9721e-01, -9.1682e-02,  2.5053e-01,\n",
      "         -9.4025e-02,  2.1956e-02,  1.6221e-01,  8.6123e-01,  8.0769e-01],\n",
      "        [ 6.5865e-02, -1.3222e-01, -2.3431e-02,  6.3937e-02, -2.4920e-01,\n",
      "         -1.1309e-01,  4.6967e-02, -7.3345e-02,  9.8533e-02,  1.3906e-01,\n",
      "         -1.0201e-01,  1.9643e-01,  8.1412e-02, -4.7505e-02, -7.7447e-03,\n",
      "         -7.9145e-03,  1.2591e-01, -4.7136e-03,  1.3464e-01,  2.2923e-01],\n",
      "        [-3.7045e-03, -6.6575e-02, -1.2814e-02, -1.7761e-03, -2.8230e-01,\n",
      "         -7.7191e-02,  7.9293e-02, -7.5752e-02, -4.4889e-02,  1.1503e-01,\n",
      "         -9.5781e-02,  6.1454e-02,  1.5036e-01, -2.8932e-02,  1.5162e-01,\n",
      "         -1.0480e-01, -9.8197e-02, -1.2749e-02,  1.5039e-01,  3.1274e-01],\n",
      "        [ 1.5411e-01, -2.2992e-02, -1.1955e-02,  1.5507e-01, -4.4506e-01,\n",
      "         -1.2439e-02, -3.6424e-02, -8.3585e-02, -6.0101e-02, -2.8241e-02,\n",
      "         -2.8315e-02,  3.6021e-01,  3.2174e-01, -7.1119e-02,  7.7190e-02,\n",
      "         -1.8370e-02, -6.5191e-02, -8.8646e-02,  9.9403e-02,  1.6261e-01],\n",
      "        [ 7.6098e-02, -1.3560e-01, -3.9053e-02, -2.5981e-03, -2.4277e-01,\n",
      "         -8.2948e-02,  2.7730e-02, -1.1569e-02, -1.6732e-02,  6.5038e-02,\n",
      "         -1.9975e-02,  1.7653e-01,  8.4160e-02, -7.9147e-02,  5.9600e-02,\n",
      "         -5.8317e-02,  4.7940e-02, -4.4631e-03,  3.2218e-02,  1.6353e-01],\n",
      "        [ 4.9901e-02, -7.1815e-02, -2.0586e-02,  3.7820e-02, -2.2845e-01,\n",
      "         -9.8679e-02,  1.4841e-02, -7.2751e-02,  2.4845e-02,  1.4928e-01,\n",
      "          7.2499e-02,  9.4369e-02,  1.6770e-01, -1.5154e-01,  9.6592e-02,\n",
      "          3.8577e-02,  2.6793e-03, -1.1277e-01,  9.1087e-02,  1.1318e-01],\n",
      "        [ 8.3241e-02, -8.4839e-02,  3.3973e-02, -1.8161e-02, -3.0317e-01,\n",
      "         -2.3558e-02,  5.5590e-02, -3.3372e-02, -8.8017e-03,  3.2397e-02,\n",
      "         -4.7059e-02,  1.7912e-01,  1.4865e-01, -9.3082e-02,  7.5371e-02,\n",
      "         -6.9854e-02,  4.5020e-02, -5.0870e-02,  1.0404e-01,  2.3294e-01],\n",
      "        [ 5.7981e-02, -5.3525e-02, -7.4961e-02, -6.8120e-02, -1.6454e-01,\n",
      "         -1.5195e-01,  2.1934e-02, -1.3876e-02,  1.3294e-01,  1.2065e-01,\n",
      "          3.7682e-03,  9.4103e-02,  1.7719e-01, -3.8767e-02,  2.6362e-02,\n",
      "          3.7373e-03,  1.0871e-01, -7.6117e-02,  7.5428e-02,  5.7986e-02]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([ 5,  0, 19, 14, 12, 11,  5, 15, 15, 10, 16, 10,  6, 10,  6,  7,  2, 11,\n",
      "         0,  5, 10,  6,  3,  4,  2,  4,  2,  3, 12,  5, 12, 11])\n",
      "tensor([[-6.1432e-02, -1.8805e-02,  2.0861e-02, -5.7333e-02, -3.4821e-01,\n",
      "          3.8807e-04,  5.3842e-02,  1.3988e-01, -7.5884e-02,  4.4583e-02,\n",
      "         -9.6072e-02,  1.2949e-03,  8.9981e-02,  3.5266e-02,  9.8877e-02,\n",
      "         -2.0706e-01,  2.1321e-02,  5.6317e-02,  1.2480e-01,  3.1377e-01],\n",
      "        [ 4.6495e-02, -1.8700e-02, -1.6483e-01, -7.3214e-02, -2.7853e-01,\n",
      "         -1.5452e-01, -4.7287e-02, -3.8343e-02, -9.7353e-02,  5.9166e-02,\n",
      "          9.5009e-04,  1.0435e-01,  2.3350e-01,  1.9467e-02,  8.4774e-02,\n",
      "          2.4559e-02, -6.7750e-02,  3.5920e-02,  3.8549e-02,  1.5525e-01],\n",
      "        [-3.3187e-03, -6.4806e-02, -9.1558e-02,  2.5927e-02, -2.2901e-01,\n",
      "         -5.8387e-02,  1.9314e-02, -9.0407e-02, -4.3562e-02,  1.1579e-01,\n",
      "          2.1076e-02,  1.1785e-01,  2.4604e-01, -1.4612e-01,  1.5087e-01,\n",
      "          4.6155e-02,  6.0372e-02,  5.2317e-03,  1.5787e-01,  1.6055e-01],\n",
      "        [ 4.7578e-02, -2.4718e-02, -6.4547e-02, -1.3682e-02, -2.0403e-01,\n",
      "         -1.4489e-01,  4.2148e-02, -7.5434e-02,  5.5100e-02,  1.7080e-01,\n",
      "         -1.6488e-02,  1.5356e-01,  2.1600e-01, -8.7656e-02,  8.6829e-02,\n",
      "          2.2694e-03,  1.0347e-01,  1.0972e-02,  1.4250e-01,  1.3101e-01],\n",
      "        [ 2.9840e-02, -4.6795e-02, -3.2829e-02, -4.6898e-02, -2.1300e-01,\n",
      "         -6.7902e-02,  1.7360e-02,  9.5437e-03,  9.3904e-02,  1.2037e-01,\n",
      "         -3.4162e-02,  8.1798e-02,  2.6985e-01, -1.5668e-01,  1.1301e-01,\n",
      "         -9.9840e-02, -1.6764e-02, -3.5650e-02,  5.4388e-02,  1.0660e-01],\n",
      "        [ 7.1188e-02, -8.8236e-02, -1.5937e-02,  2.4619e-02, -3.2381e-01,\n",
      "         -1.0715e-01,  3.7053e-02, -3.9193e-02, -3.2347e-02,  1.1882e-01,\n",
      "         -5.9809e-02,  1.5470e-01,  1.2507e-01, -3.0074e-02,  6.7682e-03,\n",
      "         -5.8945e-02,  1.7814e-03, -2.9459e-02,  6.1713e-03,  2.7842e-01],\n",
      "        [ 1.2047e-01, -7.0185e-02, -9.8738e-03, -4.5150e-03, -3.0887e-01,\n",
      "         -2.1458e-02, -5.2340e-02, -1.5990e-01,  4.4112e-02,  1.4559e-01,\n",
      "          1.3908e-02,  2.0567e-01,  2.6917e-01, -1.1143e-01,  1.2803e-01,\n",
      "          1.3319e-01,  5.1122e-02, -1.8057e-02,  1.8463e-01,  1.4934e-01],\n",
      "        [ 5.1982e-02, -8.4883e-02,  2.3293e-02, -5.7131e-03, -2.6716e-01,\n",
      "         -5.2754e-02,  9.0786e-03, -6.8207e-02,  2.5966e-02,  2.0213e-01,\n",
      "         -1.0246e-01,  1.1395e-01,  2.9332e-01, -1.5704e-01,  1.3035e-01,\n",
      "          6.7963e-02,  7.2346e-02, -1.3738e-01,  1.6870e-01,  2.2517e-01],\n",
      "        [ 1.7034e-01, -7.2994e-02, -5.7051e-02, -4.0698e-02, -8.0427e-02,\n",
      "          1.1709e-02,  7.9126e-02, -9.2202e-02,  1.1253e-01,  2.0616e-01,\n",
      "         -1.4901e-01,  1.9770e-02,  1.1411e-01, -3.2481e-02,  8.7919e-02,\n",
      "         -1.9165e-01, -4.0612e-03,  5.5028e-02,  9.9842e-02,  1.6722e-01],\n",
      "        [ 2.2699e-02, -2.2742e-02, -7.3539e-02, -1.1309e-01, -2.1536e-01,\n",
      "         -1.1238e-01, -1.0149e-02, -7.5946e-02, -7.9847e-02,  1.0248e-01,\n",
      "          1.2477e-02,  1.7230e-01,  3.3919e-01, -1.4359e-01,  8.4024e-02,\n",
      "          1.3669e-02, -7.1457e-03, -4.6727e-02,  6.1695e-02,  1.9522e-01],\n",
      "        [-6.6803e-02,  1.2207e-02,  2.5370e-02,  1.2943e-02, -5.1498e-01,\n",
      "         -8.4507e-02,  2.5909e-02, -1.5586e-01, -5.2045e-02,  1.1611e-01,\n",
      "         -3.6132e-02,  2.0957e-01,  3.9823e-01, -5.6491e-02,  1.3654e-01,\n",
      "          2.2377e-02, -1.8261e-01, -2.3420e-02,  3.5014e-01,  4.2130e-01],\n",
      "        [ 1.0407e-01, -5.7986e-02, -9.0968e-02, -9.0285e-03, -2.6204e-01,\n",
      "         -1.0330e-01, -1.8680e-02, -1.3810e-01,  3.6678e-02,  1.7963e-01,\n",
      "         -7.5377e-02,  1.7269e-01,  3.3204e-01, -4.3213e-02,  7.2045e-02,\n",
      "         -1.4228e-03, -2.1387e-02, -5.2753e-02,  1.8127e-01,  1.4384e-01],\n",
      "        [ 2.9461e-02, -1.2234e-01,  7.9394e-03,  5.8383e-02, -3.4559e-01,\n",
      "         -1.2054e-01, -8.3683e-02, -9.3114e-02,  3.3875e-02,  1.7334e-01,\n",
      "         -2.4278e-02,  2.1740e-01,  2.5373e-01, -4.2568e-02,  1.0528e-01,\n",
      "          7.1983e-02, -6.9103e-02,  1.8623e-02,  6.4356e-02,  2.1969e-01],\n",
      "        [-7.6187e-02, -1.2039e-01, -8.2634e-02,  3.9201e-02, -4.4212e-01,\n",
      "         -1.0380e-01,  5.7964e-02,  3.2193e-02, -2.4117e-02,  1.4832e-01,\n",
      "          7.0986e-02,  2.2136e-01,  2.3439e-01, -2.4951e-02,  2.1079e-02,\n",
      "         -7.3793e-02, -2.4515e-02, -4.0734e-02,  1.6176e-01,  2.6833e-01],\n",
      "        [-1.4639e-02, -8.3216e-02,  2.0265e-02,  5.4880e-02, -3.0558e-01,\n",
      "         -1.5872e-01,  4.2682e-02,  1.3117e-02,  1.5476e-01,  8.0485e-02,\n",
      "         -1.6243e-02,  2.3299e-01,  1.6111e-01, -8.9434e-02,  5.0930e-02,\n",
      "          2.1407e-02,  1.9552e-03, -8.9120e-02,  5.9318e-02,  1.6178e-01],\n",
      "        [-6.8509e-02,  7.5214e-03, -4.2983e-02, -2.0744e-03, -3.9544e-01,\n",
      "         -3.8940e-02,  1.0752e-02,  2.5737e-03, -9.4169e-02,  8.3730e-02,\n",
      "         -2.4500e-02,  2.0446e-01,  1.6771e-01, -1.0472e-01,  7.9278e-02,\n",
      "         -4.7763e-03,  3.5380e-02,  4.4578e-02,  2.1081e-01,  1.3516e-01],\n",
      "        [-1.3000e-02, -1.3323e-01, -1.2935e-01,  1.4859e-01, -3.0308e-01,\n",
      "         -5.1960e-02,  6.2530e-02,  1.3682e-02,  1.0297e-01,  1.2154e-01,\n",
      "         -7.4307e-02,  1.8904e-01,  1.9292e-01, -2.4482e-01,  3.1961e-02,\n",
      "          2.4210e-02,  4.3222e-02,  5.2422e-02,  8.4997e-02,  3.1511e-01],\n",
      "        [ 6.6983e-02, -2.0584e-03, -3.4217e-02,  2.9315e-02, -3.0068e-01,\n",
      "         -1.4289e-01,  1.3993e-02, -4.8435e-02,  1.7023e-02,  1.7712e-01,\n",
      "         -2.3819e-02,  1.4552e-01,  1.7937e-01, -9.8431e-02,  1.1449e-01,\n",
      "         -3.8765e-02, -1.2824e-01, -2.3711e-04,  1.4640e-01,  2.3447e-01],\n",
      "        [ 1.2895e-02, -3.9555e-02, -7.8708e-02, -7.6390e-02, -9.0585e-02,\n",
      "         -8.4478e-02, -4.0615e-02, -3.3575e-02, -2.5702e-02,  9.9138e-02,\n",
      "         -8.4827e-02,  1.3667e-01,  2.2214e-01, -8.8059e-02, -4.2832e-02,\n",
      "         -6.7287e-02,  6.6179e-03, -2.5064e-02, -1.6244e-02,  2.6428e-02],\n",
      "        [ 7.7745e-02, -6.0075e-03,  3.5625e-02,  4.8467e-02, -3.5820e-01,\n",
      "         -1.0058e-01,  1.9198e-02, -4.7195e-02,  4.5480e-02,  1.2114e-01,\n",
      "         -3.2198e-02,  2.6385e-01,  1.9637e-01, -1.2442e-01,  1.0766e-01,\n",
      "          3.5184e-02, -2.4318e-02,  1.1789e-02,  1.4358e-01,  2.2353e-01],\n",
      "        [ 8.9502e-02, -9.6441e-02, -8.9708e-02,  3.7766e-03, -2.4497e-01,\n",
      "         -5.8605e-02,  3.8315e-02, -8.1021e-02,  1.4482e-02,  9.0808e-02,\n",
      "          1.3139e-01,  6.2306e-02,  1.1987e-01, -6.8317e-02,  8.4811e-02,\n",
      "         -6.8469e-02,  6.9149e-02, -1.4580e-02, -1.2315e-02,  1.2226e-01],\n",
      "        [ 3.3908e-02, -6.6073e-02,  4.0911e-02,  9.9829e-02, -3.4394e-01,\n",
      "         -2.1409e-02, -2.6822e-02, -4.2792e-02,  4.5341e-02,  1.4977e-01,\n",
      "         -7.6407e-02,  2.0955e-01,  2.3549e-01, -1.2890e-01,  9.8031e-02,\n",
      "         -1.2517e-02,  1.7820e-02, -2.8334e-02,  2.7740e-01,  2.9893e-01],\n",
      "        [ 4.0281e-02, -8.7155e-02, -4.8448e-02, -1.7256e-02, -2.8759e-01,\n",
      "         -3.0691e-02,  2.1028e-02, -3.7690e-02,  9.6711e-02,  3.5188e-02,\n",
      "         -1.0594e-01,  1.3713e-01,  2.0546e-01, -1.0848e-01, -4.3551e-03,\n",
      "         -2.4756e-02,  6.3510e-02, -5.4405e-02,  5.6844e-03,  1.7256e-01],\n",
      "        [-2.2531e-02, -5.5266e-02,  7.3840e-02, -2.5110e-03, -2.6285e-01,\n",
      "         -5.4537e-02,  7.8898e-04,  2.0771e-02,  6.5886e-03,  1.2760e-01,\n",
      "         -3.1929e-02,  1.4086e-01,  1.2140e-01, -1.6418e-01,  7.2403e-02,\n",
      "          1.2032e-01,  5.8877e-02, -8.8942e-02,  1.2663e-01,  1.5228e-01],\n",
      "        [ 6.2016e-02, -3.2882e-02,  4.7878e-02,  6.7111e-02, -1.8526e-01,\n",
      "         -4.8999e-02, -1.3265e-02,  5.2888e-03, -1.2321e-02,  1.0735e-01,\n",
      "          1.6633e-02,  2.2525e-01,  1.9528e-01, -4.3468e-02,  7.5543e-02,\n",
      "         -2.1328e-02,  8.0017e-03, -1.4974e-01,  3.4464e-02,  7.1574e-02],\n",
      "        [ 1.0307e-02, -2.5049e-02, -5.7802e-03,  2.0476e-02, -1.7203e-01,\n",
      "         -9.6140e-02,  1.6058e-02, -2.6667e-02, -6.3329e-02,  1.2554e-01,\n",
      "         -8.4711e-02,  8.5388e-02,  1.6327e-01, -6.7416e-02,  5.2882e-02,\n",
      "         -4.0841e-02, -9.0601e-03, -7.8940e-02,  6.2541e-02,  7.3543e-02],\n",
      "        [ 1.3784e-01,  9.2135e-03,  3.4391e-03,  1.8821e-01, -3.7242e-01,\n",
      "         -6.2907e-02, -4.2396e-02, -7.3186e-02, -3.1420e-02,  2.1348e-01,\n",
      "         -7.3936e-02,  2.6229e-01,  3.4540e-01, -7.7701e-02,  4.4379e-02,\n",
      "         -2.5055e-02, -2.2252e-02,  1.7216e-03,  2.1594e-01,  2.0965e-01],\n",
      "        [ 4.7182e-02, -6.8452e-02, -5.1511e-02, -3.4734e-02, -2.5439e-01,\n",
      "         -7.6170e-02,  3.6340e-02, -2.6838e-02, -3.2553e-02,  9.6361e-02,\n",
      "          4.3623e-02,  1.6833e-01,  2.0306e-01, -5.5003e-02,  1.2995e-01,\n",
      "          2.5921e-02,  1.1745e-02, -6.9779e-03,  1.5049e-01,  1.2655e-01],\n",
      "        [ 9.1993e-02, -7.6175e-02, -1.2139e-01,  2.3308e-02, -1.1597e-01,\n",
      "         -6.0751e-02, -3.1726e-02, -4.2312e-02, -3.3077e-02,  1.7846e-01,\n",
      "         -1.5492e-01,  1.3975e-01,  3.0474e-01, -2.2202e-02,  8.3886e-02,\n",
      "         -6.9912e-02, -7.2291e-02,  1.7687e-03,  1.6004e-02,  1.1331e-01],\n",
      "        [ 5.0581e-02, -6.4078e-02, -1.2548e-01,  3.6516e-02, -2.0921e-01,\n",
      "         -1.2195e-01, -9.0293e-03, -6.3496e-02,  3.7365e-02,  1.6883e-01,\n",
      "         -8.9797e-02,  1.1338e-01,  2.3623e-01, -1.0250e-01,  8.9998e-02,\n",
      "          3.9994e-02, -2.9184e-02, -6.8900e-02,  6.1615e-02,  6.9288e-02],\n",
      "        [ 8.1286e-02, -1.1599e-01, -7.2639e-02,  3.4571e-03, -3.5938e-01,\n",
      "         -6.4930e-02, -2.7339e-02, -1.0050e-01, -2.3863e-02,  6.7656e-02,\n",
      "          3.8969e-02,  1.8497e-01,  2.1244e-01, -9.9068e-02,  9.1091e-02,\n",
      "          4.1135e-02,  4.1348e-02, -4.8692e-02,  1.2137e-01,  1.4733e-01],\n",
      "        [ 8.4791e-02, -8.6917e-02, -9.6417e-03, -2.4143e-02, -1.9274e-01,\n",
      "         -4.2175e-02, -3.6567e-02, -1.6850e-01,  1.6767e-02,  1.1529e-01,\n",
      "         -6.3077e-02,  1.1569e-01,  2.8398e-01, -8.3666e-02,  6.8682e-02,\n",
      "          1.3446e-02,  2.2250e-02, -3.2893e-02,  3.1462e-02,  7.9960e-02]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([15, 17, 14, 10, 10,  7, 18,  8, 10,  2, 17, 18,  4,  2, 14, 14,  9, 16,\n",
      "         3, 12,  0, 18,  0,  5, 14,  5, 17,  5,  6, 11,  1, 18])\n",
      "tensor([[ 3.5331e-02, -2.1799e-01, -1.1064e-01, -4.8970e-02, -2.9076e-01,\n",
      "          1.1917e-02, -5.5776e-02, -1.7112e-01, -1.0047e-02,  9.3353e-02,\n",
      "         -4.3936e-02,  1.2873e-01,  3.1689e-01, -1.6108e-01,  2.7286e-01,\n",
      "          1.0951e-01,  1.4368e-01, -4.2289e-02,  1.6733e-01,  1.4055e-01],\n",
      "        [ 7.8692e-02, -8.6685e-02, -9.1465e-02,  3.3304e-02, -3.1016e-01,\n",
      "         -3.6921e-02, -5.2238e-02, -1.1242e-01,  5.1178e-02,  1.1238e-01,\n",
      "         -3.5921e-02,  1.3235e-01,  2.7770e-01, -1.1305e-01,  1.5576e-01,\n",
      "          2.5670e-02, -1.4819e-02, -5.8182e-02,  1.5181e-01,  1.7283e-01],\n",
      "        [ 5.7282e-02, -7.7451e-02, -1.0025e-01,  1.1676e-02, -3.0049e-01,\n",
      "         -1.4930e-01, -5.1804e-03, -9.2291e-02, -7.5443e-03,  1.6285e-01,\n",
      "         -9.8328e-02,  1.7919e-01,  2.3757e-01, -1.4746e-01,  3.8656e-02,\n",
      "          2.4643e-02, -6.5988e-02, -3.7515e-02,  1.6543e-01,  1.8131e-01],\n",
      "        [ 3.7690e-02, -1.2526e-01,  4.6616e-02, -1.6381e-02, -3.1320e-01,\n",
      "         -5.4782e-02,  2.7401e-02, -7.0953e-02, -9.4940e-02,  7.5703e-02,\n",
      "         -4.6674e-02,  1.3850e-01,  1.5158e-01, -8.5908e-02,  1.6983e-01,\n",
      "          6.4338e-02,  6.8050e-02, -6.0670e-02,  4.5927e-02,  2.2499e-01],\n",
      "        [ 3.5147e-02, -1.0723e-02, -3.2163e-02, -2.1513e-02, -3.3145e-01,\n",
      "         -1.2135e-01,  1.4898e-02, -1.0161e-01,  7.7751e-02,  1.5828e-01,\n",
      "         -1.4792e-02,  2.0492e-01,  2.5962e-01, -1.2824e-01,  7.7664e-02,\n",
      "         -2.5061e-03, -1.7195e-02,  3.2649e-02,  1.3650e-01,  2.1737e-01],\n",
      "        [ 4.4166e-02,  5.3538e-02,  4.3330e-02,  9.2694e-02, -3.5596e-01,\n",
      "         -1.1668e-01,  4.1210e-02,  1.0174e-01,  8.1869e-03,  1.0276e-01,\n",
      "         -6.8422e-02,  1.5718e-01,  1.1480e-01, -1.5833e-01,  9.8150e-03,\n",
      "         -6.8783e-02, -1.3686e-01, -7.7385e-03,  1.2287e-01,  2.0991e-01],\n",
      "        [ 5.0826e-02, -5.0485e-02, -2.7737e-02, -7.0280e-02, -1.9842e-01,\n",
      "         -7.8815e-02, -5.0667e-03, -1.2204e-01, -2.4103e-02,  1.3337e-01,\n",
      "         -1.0452e-02,  1.1104e-01,  2.3053e-01, -7.0895e-02,  9.5041e-02,\n",
      "          2.2614e-02, -3.3827e-03, -3.8587e-02,  9.6489e-02,  1.0220e-01],\n",
      "        [ 1.0651e-01, -5.6740e-02,  1.5746e-03, -6.4671e-03, -2.5678e-01,\n",
      "         -1.1828e-01, -1.7183e-02, -1.1463e-01,  3.7696e-02,  1.3305e-01,\n",
      "         -3.2509e-02,  8.6115e-02,  2.5304e-01, -6.3892e-02,  1.7103e-01,\n",
      "         -1.3636e-02, -1.9169e-02, -9.2221e-02, -2.3808e-02,  1.4885e-01],\n",
      "        [ 2.8390e-02, -5.5337e-02, -1.3973e-01, -1.1251e-01, -2.1497e-01,\n",
      "         -1.0387e-01, -2.7053e-02, -1.4671e-01,  4.0190e-02,  7.2241e-02,\n",
      "         -2.1665e-02,  1.0157e-01,  2.3938e-01, -1.0777e-01,  5.1683e-02,\n",
      "          2.1469e-02,  6.9868e-02, -7.7845e-03,  1.1789e-01,  7.8557e-02],\n",
      "        [ 1.7588e-02, -8.0305e-02,  7.1093e-02,  1.2576e-01, -3.9838e-01,\n",
      "         -9.0844e-02,  9.7073e-03, -8.5148e-02, -3.4080e-02,  1.6406e-01,\n",
      "         -1.0333e-01,  2.4270e-01,  2.2227e-01, -8.5643e-02,  7.9465e-02,\n",
      "         -5.6646e-02, -5.7537e-02,  2.5904e-02,  2.5247e-01,  3.2116e-01],\n",
      "        [ 7.1141e-02, -3.5043e-02, -2.8700e-02,  3.2927e-03, -2.5579e-01,\n",
      "         -7.4385e-02,  4.3175e-02, -1.1609e-01,  6.0289e-02,  1.5265e-01,\n",
      "         -1.6513e-02,  2.0731e-01,  2.6932e-01, -1.2626e-01,  1.0599e-01,\n",
      "          1.3419e-01, -4.5909e-02, -3.1986e-02,  1.6464e-01,  2.2854e-01],\n",
      "        [ 7.8049e-02, -1.1174e-01, -6.8859e-02, -8.3059e-03, -2.5000e-01,\n",
      "         -9.4614e-02, -2.3574e-02,  7.3436e-03, -6.6499e-04,  1.2247e-01,\n",
      "         -3.7944e-02,  9.9726e-02,  2.0038e-01, -9.9048e-02,  1.1961e-01,\n",
      "         -2.5366e-02, -4.4562e-02, -1.1501e-01, -4.1992e-03,  1.0674e-01],\n",
      "        [ 5.3453e-02, -8.1741e-02, -5.1261e-02,  1.1958e-02, -2.7274e-01,\n",
      "         -4.6053e-02, -5.7949e-02, -3.6667e-02,  4.2218e-02,  9.4835e-02,\n",
      "          7.3922e-02,  1.8465e-01,  1.8834e-01, -1.1649e-01,  1.1433e-01,\n",
      "         -6.6255e-02,  6.8079e-02,  5.2046e-04,  1.1923e-01,  1.7536e-01],\n",
      "        [ 5.1689e-02, -6.3671e-03, -4.2432e-02,  1.3476e-01, -4.3588e-01,\n",
      "         -1.1219e-01, -4.3925e-02, -6.2625e-02, -5.6224e-02,  1.2137e-01,\n",
      "         -5.9990e-02,  2.0705e-01,  3.3410e-01, -1.3212e-01,  4.5871e-02,\n",
      "         -7.5185e-03, -7.7644e-03, -2.0663e-03,  1.2943e-01,  2.0772e-01],\n",
      "        [ 1.7108e-01, -7.8363e-02, -6.6983e-02,  1.2977e-01, -3.5179e-01,\n",
      "         -4.9236e-02,  2.1694e-02, -1.6007e-01,  7.4561e-02,  1.8321e-01,\n",
      "         -4.8476e-02,  2.0114e-01,  3.0634e-01, -2.5635e-02, -7.6525e-03,\n",
      "         -2.4136e-02,  2.2840e-03, -1.2951e-02,  2.0377e-01,  2.7755e-01],\n",
      "        [ 3.2185e-02, -4.9852e-02, -1.3459e-01, -3.8139e-02, -2.2390e-01,\n",
      "         -6.8739e-02,  3.5482e-02, -3.1628e-02, -1.3695e-02, -2.3441e-02,\n",
      "          5.1515e-02,  5.0565e-02,  1.6825e-01, -1.3691e-01,  1.0253e-01,\n",
      "         -1.2631e-02,  8.5487e-03, -5.3856e-02, -5.1653e-03,  1.1525e-01],\n",
      "        [ 6.9531e-02, -6.7138e-02, -6.5754e-02, -3.3524e-02, -2.2471e-01,\n",
      "         -9.0934e-02, -4.0272e-02, -4.4810e-02,  2.2213e-02,  1.1443e-01,\n",
      "         -7.8913e-02,  1.0685e-01,  2.2475e-01, -1.1316e-01,  1.1136e-01,\n",
      "          3.0614e-02,  5.3370e-02, -1.4916e-02,  7.8893e-02,  1.5671e-01],\n",
      "        [ 2.4483e-02, -7.3314e-02,  9.6760e-02,  1.6238e-01, -5.4684e-01,\n",
      "         -4.2102e-02, -2.6518e-02, -1.5984e-01,  2.1910e-03,  1.3144e-01,\n",
      "         -3.0258e-02,  2.4719e-01,  2.9243e-01, -8.7815e-02,  1.2708e-01,\n",
      "         -5.0116e-02,  5.4210e-02,  6.8232e-02,  3.3368e-01,  3.4010e-01],\n",
      "        [ 2.2880e-02,  3.2296e-02, -5.4225e-02,  8.6464e-02, -3.5210e-01,\n",
      "         -1.3155e-01,  2.3720e-02, -1.2892e-02,  6.5219e-02,  1.4971e-01,\n",
      "         -4.6539e-02,  2.0891e-01,  2.3794e-01, -8.3778e-02,  6.2630e-02,\n",
      "         -7.5123e-02, -1.1317e-01,  4.1638e-03,  9.9903e-02,  2.2476e-01],\n",
      "        [ 4.7672e-02, -1.8496e-02, -8.8555e-02, -5.7882e-02, -2.8803e-01,\n",
      "         -1.0747e-01, -2.8783e-02, -4.2144e-02,  3.2326e-02,  9.4181e-02,\n",
      "         -1.2953e-02,  1.9804e-01,  2.7403e-01, -7.1777e-02, -6.8890e-04,\n",
      "          5.3440e-02, -6.4089e-02, -4.3116e-03,  8.0396e-02,  1.3303e-01],\n",
      "        [-3.6741e-02, -2.0646e-02, -1.0614e-01,  2.8679e-02, -1.8735e-01,\n",
      "         -1.1645e-01,  4.9493e-02, -5.8919e-02,  1.5583e-02,  1.3241e-01,\n",
      "         -1.2097e-02,  1.6505e-01,  1.7498e-01, -5.6814e-02,  7.0965e-02,\n",
      "         -7.2030e-02, -5.4487e-02,  5.6187e-02,  1.2576e-01,  2.0640e-01],\n",
      "        [ 6.6697e-02, -1.2983e-01, -1.2747e-01, -5.5109e-02, -2.4647e-01,\n",
      "         -6.3469e-02,  4.4952e-02, -1.2691e-01, -2.4727e-02,  7.5125e-02,\n",
      "          4.1872e-02,  7.6496e-02,  2.4326e-01, -1.1600e-01,  6.0489e-02,\n",
      "          9.5840e-02,  1.1447e-01, -5.9102e-02,  8.8918e-02,  1.0326e-01],\n",
      "        [-4.6222e-02, -7.1756e-02, -5.5868e-02,  2.2718e-02, -2.8127e-01,\n",
      "         -8.2751e-02, -7.2408e-02, -3.3163e-02, -3.8015e-02,  1.2834e-01,\n",
      "         -4.9215e-02,  1.7198e-01,  2.4111e-01, -5.9295e-02,  1.4482e-01,\n",
      "         -4.4136e-02,  5.9391e-03, -4.2030e-02,  9.2869e-02,  1.3102e-01],\n",
      "        [ 2.4212e-02, -9.6422e-02,  1.1853e-02,  1.2517e-01, -3.5669e-01,\n",
      "         -5.3815e-02,  2.2798e-02, -2.0435e-04,  5.1607e-02,  1.2044e-01,\n",
      "         -4.3289e-02,  2.7741e-01,  2.5648e-01, -1.1355e-01,  6.1721e-02,\n",
      "         -3.1517e-02, -1.2610e-02, -2.0781e-02,  1.9130e-01,  1.9931e-01],\n",
      "        [ 3.5433e-02,  4.7198e-02,  2.6045e-01,  1.3848e-01, -5.1773e-01,\n",
      "         -5.8603e-02, -1.0911e-01,  2.1237e-02, -1.2521e-02,  1.7191e-01,\n",
      "         -2.1090e-01,  2.6289e-01,  4.7499e-02, -4.7229e-02,  1.5357e-01,\n",
      "         -8.8006e-02, -6.3512e-02,  6.5010e-02, -6.2139e-03,  2.5108e-01],\n",
      "        [ 3.7434e-02, -1.2313e-01, -1.4075e-01,  6.2776e-03, -1.7452e-01,\n",
      "         -2.1004e-02,  4.7581e-02, -5.0173e-02,  1.9169e-02,  1.3534e-01,\n",
      "         -7.4663e-02,  1.3335e-01,  1.8228e-01, -7.2713e-02,  6.5468e-02,\n",
      "          4.2422e-03,  4.2092e-02, -6.0635e-02,  1.0067e-01,  1.5393e-01],\n",
      "        [-5.1816e-02, -1.9131e-02,  1.5653e-01,  1.1024e-01, -3.9904e-01,\n",
      "         -1.3204e-01, -5.1012e-02,  3.5459e-03, -4.5014e-02,  1.3751e-01,\n",
      "         -1.5303e-01,  1.4046e-01,  1.9794e-01, -8.3088e-02,  1.4286e-01,\n",
      "         -9.6927e-02, -2.4335e-02, -5.1211e-02,  8.6067e-02,  2.6921e-01],\n",
      "        [ 3.6174e-02, -7.7797e-03, -1.0012e-02,  1.2205e-01, -3.3551e-01,\n",
      "         -1.0156e-01, -1.2313e-03, -5.6164e-02,  1.0671e-01,  1.8046e-01,\n",
      "         -6.8001e-02,  2.4557e-01,  2.3180e-01, -1.0956e-01,  9.0111e-02,\n",
      "         -3.2148e-02, -3.8007e-02, -5.7948e-02,  1.8049e-01,  2.0231e-01],\n",
      "        [ 8.9941e-02, -6.9940e-02, -7.7338e-02, -3.3106e-02, -2.5771e-01,\n",
      "         -1.7089e-01,  2.0465e-02, -1.0242e-01, -1.2018e-02,  1.3122e-01,\n",
      "         -5.1062e-02,  1.1281e-01,  1.9312e-01, -9.0106e-02,  2.9013e-02,\n",
      "          5.0014e-02, -7.5041e-02,  4.8515e-02,  8.1357e-02,  2.6719e-01],\n",
      "        [ 6.5018e-02,  5.6481e-03,  4.9413e-02, -1.4672e-02, -2.4974e-01,\n",
      "         -3.0432e-02, -2.4623e-02, -9.1363e-02, -3.1986e-02,  1.4335e-01,\n",
      "         -3.9135e-03,  1.4933e-01,  2.5790e-01, -5.6646e-02,  5.9006e-02,\n",
      "         -8.5856e-04, -3.3573e-02,  3.2372e-02,  1.4522e-01,  2.3767e-01],\n",
      "        [ 7.2743e-02, -5.4558e-02, -2.9617e-03, -1.0579e-01, -2.2664e-01,\n",
      "         -6.9601e-02,  7.5366e-02,  1.1202e-02, -1.2786e-03,  1.1609e-01,\n",
      "         -7.7547e-02,  1.5320e-01,  1.9795e-01, -1.5488e-01,  3.5553e-02,\n",
      "          4.3039e-02,  9.0297e-02, -9.1506e-02,  1.2641e-02,  1.7630e-01],\n",
      "        [ 1.7219e-02, -6.5606e-02, -1.2283e-01,  3.8063e-02, -3.4452e-01,\n",
      "         -9.1829e-02,  1.4284e-02, -5.0798e-02,  9.4427e-03,  7.7364e-02,\n",
      "          1.3252e-02,  1.6078e-01,  2.1765e-01, -5.8133e-02,  3.9162e-02,\n",
      "          3.0109e-02,  1.2146e-01, -6.4210e-02,  1.4332e-01,  9.6665e-02]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([17, 12, 17,  4,  2,  4, 16, 18, 16,  1, 13,  0, 19,  8, 19, 11, 11, 19,\n",
      "         8, 10, 16, 16, 12,  1,  5,  7,  2, 17,  5,  8,  1, 12])\n",
      "tensor([[ 2.3158e-02, -4.3591e-02, -6.2131e-02, -4.7098e-02, -2.8924e-01,\n",
      "         -1.7198e-01,  8.1345e-02, -2.8764e-02,  5.4896e-02,  1.0406e-01,\n",
      "         -4.4720e-02,  1.4177e-01,  1.0426e-01, -1.4658e-01,  7.6794e-02,\n",
      "          4.8040e-02,  9.0881e-02, -5.9574e-02,  1.2451e-01,  1.5782e-01],\n",
      "        [-4.6747e-02, -7.8755e-02,  8.9356e-03, -5.8249e-02, -2.8964e-01,\n",
      "         -1.7177e-01, -4.7848e-02,  5.9533e-02, -9.0074e-02,  1.4276e-01,\n",
      "         -3.9011e-02,  6.0987e-02,  2.1526e-01,  6.9131e-03,  2.1332e-01,\n",
      "         -1.3299e-01,  3.7854e-02,  1.3480e-01,  1.9092e-01,  9.3363e-02],\n",
      "        [ 2.3062e-02, -4.3475e-02, -3.2836e-02,  1.5477e-02, -3.0846e-01,\n",
      "         -2.4616e-02,  4.8765e-02, -2.1059e-02, -6.1344e-02,  2.0056e-02,\n",
      "         -8.3232e-02,  1.7348e-01,  2.0642e-01, -1.6899e-01,  6.2431e-02,\n",
      "         -7.7532e-02,  7.3477e-02, -1.6869e-02,  1.3318e-01,  2.8215e-01],\n",
      "        [ 1.5683e-02, -9.7986e-02,  1.3697e-01,  5.1907e-02, -3.4277e-01,\n",
      "         -6.2727e-02,  4.4339e-02, -1.1107e-02, -1.0497e-01,  1.0662e-01,\n",
      "          2.7815e-03,  1.6775e-01,  2.5084e-01, -1.0501e-01,  1.3775e-01,\n",
      "         -2.5506e-02, -2.1527e-02,  1.9331e-03,  2.4775e-01,  2.4555e-01],\n",
      "        [ 2.4624e-02, -5.5106e-04,  1.0616e-01,  1.6838e-02, -2.5717e-01,\n",
      "         -2.4334e-01,  1.1863e-01,  9.0193e-02, -4.8803e-02,  5.4072e-02,\n",
      "         -1.1647e-01,  2.3181e-01,  1.7113e-01, -6.7223e-02,  2.1276e-02,\n",
      "          8.8399e-02, -6.0493e-02, -8.5301e-02,  9.4843e-02,  4.8475e-02],\n",
      "        [ 5.1700e-02, -3.5539e-02, -3.4625e-03,  2.4989e-02, -1.8698e-01,\n",
      "         -1.8592e-01, -5.4780e-03, -1.9971e-02,  1.6784e-01,  2.1542e-01,\n",
      "         -1.4048e-02,  1.7982e-01,  1.6341e-01, -5.8410e-04,  1.0051e-01,\n",
      "          6.6396e-02,  6.9442e-02, -9.2407e-02, -5.7858e-02,  6.1032e-02],\n",
      "        [-6.2134e-03, -1.1245e-02, -3.3252e-02, -3.8547e-02, -2.5820e-01,\n",
      "         -9.9064e-02,  3.3362e-02, -4.5276e-02,  3.6453e-02,  1.2423e-01,\n",
      "          9.4782e-02,  1.5948e-01,  1.1375e-01, -7.6321e-02,  9.0278e-02,\n",
      "         -5.7116e-02,  3.6680e-02, -7.3019e-02,  8.5858e-02,  1.3549e-01],\n",
      "        [-2.4706e-02, -1.3868e-01, -2.1375e-01, -2.6625e-04, -1.6569e-01,\n",
      "         -2.2508e-01, -7.2446e-02, -2.4614e-03, -1.4692e-01,  1.4270e-01,\n",
      "         -1.3362e-01,  2.0131e-01,  3.4799e-01, -7.1698e-03, -1.0817e-02,\n",
      "          1.3098e-02, -5.4761e-02,  4.7262e-02,  2.8754e-02,  1.0136e-01],\n",
      "        [ 2.5281e-02, -5.8540e-02, -1.6879e-02,  2.2540e-03, -2.5383e-01,\n",
      "         -6.4660e-02,  3.6326e-02, -7.6543e-02,  4.9441e-02,  1.0521e-01,\n",
      "          1.7482e-02,  1.7487e-01,  1.8915e-01, -8.0722e-02,  5.5227e-02,\n",
      "          4.1960e-02,  9.2705e-03, -3.2979e-02,  8.6517e-02,  9.7401e-02],\n",
      "        [-4.2971e-02, -4.1917e-02, -6.4329e-02,  8.0822e-02, -3.4082e-01,\n",
      "         -1.2586e-01,  3.0543e-02, -4.7625e-02, -3.7488e-02,  8.7574e-02,\n",
      "          5.0202e-02,  1.8898e-01,  1.7344e-01, -7.4319e-02,  7.8125e-02,\n",
      "         -4.6251e-02,  1.5663e-02,  4.7354e-02,  7.5887e-02,  1.7244e-01],\n",
      "        [ 5.2219e-02, -3.7452e-02,  1.5710e-02,  3.3809e-02, -3.4551e-01,\n",
      "         -7.1974e-02,  1.0401e-02, -8.0473e-02, -3.9764e-02,  1.4387e-01,\n",
      "          2.2137e-02,  1.3817e-01,  2.8733e-01, -1.5556e-01,  1.0649e-01,\n",
      "          9.2585e-02, -4.6406e-05, -4.6144e-02,  1.3500e-01,  1.7957e-01],\n",
      "        [-3.0860e-02, -7.1357e-03, -9.3902e-02,  7.9762e-03, -2.6427e-01,\n",
      "         -1.5592e-01,  4.0965e-02,  5.8805e-03,  4.6216e-04,  1.1137e-01,\n",
      "         -9.7905e-02,  1.7421e-01,  1.3648e-01, -6.3872e-02,  7.4409e-02,\n",
      "         -1.6557e-03,  2.8529e-02, -2.5489e-02,  8.1791e-02,  5.8396e-02],\n",
      "        [ 9.6139e-02, -1.0839e-01, -4.1564e-02,  1.0712e-01, -3.2439e-01,\n",
      "         -1.0345e-01,  2.8954e-02, -9.4301e-02,  7.0948e-02,  1.4447e-01,\n",
      "         -7.1723e-02,  1.2509e-01,  2.5284e-01, -5.0109e-02,  3.9406e-02,\n",
      "          3.5314e-02, -5.2403e-02, -1.0546e-01,  1.2720e-01,  1.9556e-01],\n",
      "        [ 3.1417e-02, -5.9911e-02, -1.1777e-01, -5.1458e-02, -2.5079e-01,\n",
      "          8.2148e-03, -9.0254e-02, -8.9552e-02,  2.0877e-02,  6.5901e-02,\n",
      "          3.8617e-02,  7.3751e-02,  1.8375e-01,  1.5533e-02, -3.5665e-02,\n",
      "         -3.2353e-02,  6.0585e-02,  1.2604e-02,  5.6485e-02,  9.1285e-02],\n",
      "        [ 8.7306e-02, -8.5243e-02, -7.4127e-02, -1.9927e-02, -2.3850e-01,\n",
      "         -8.6128e-02,  1.5962e-02, -6.8224e-02, -2.9686e-02,  1.0795e-01,\n",
      "         -4.5485e-02,  1.5028e-01,  2.0026e-01, -9.4089e-02,  9.9840e-02,\n",
      "         -2.2964e-02,  1.9921e-02,  4.5955e-02,  1.3699e-01,  1.6902e-01],\n",
      "        [ 2.4924e-02, -8.2563e-02, -8.3516e-02,  3.2914e-02, -1.4814e-01,\n",
      "         -3.9029e-02,  5.4208e-02, -7.2404e-02, -4.4038e-02,  1.1384e-01,\n",
      "         -1.0816e-01,  1.4682e-01,  2.5829e-01, -9.6851e-02,  2.5323e-02,\n",
      "         -9.0862e-02,  4.5547e-03, -9.3569e-02,  1.2318e-01,  4.7159e-02],\n",
      "        [ 8.1913e-02, -7.4411e-02, -3.8161e-02, -3.9335e-02, -2.1221e-01,\n",
      "         -1.1737e-01,  5.5956e-02, -4.2628e-02, -2.3928e-02,  9.0834e-02,\n",
      "         -1.9105e-02,  1.4161e-01,  1.9849e-01, -8.5358e-02,  9.4606e-02,\n",
      "         -2.1384e-02,  3.0718e-02,  3.2917e-02,  1.3952e-02,  1.6958e-01],\n",
      "        [ 2.4627e-02, -1.1250e-01, -3.0002e-03, -1.0981e-02, -2.5372e-01,\n",
      "         -1.8780e-01,  5.4657e-03, -5.9791e-02,  1.3110e-02,  1.2750e-01,\n",
      "         -5.5118e-02,  2.2844e-01,  2.8903e-01, -7.9433e-02,  2.3792e-02,\n",
      "          1.2185e-01,  2.1915e-02, -4.7342e-02,  3.1795e-02,  7.9677e-02],\n",
      "        [-8.5934e-02,  3.7650e-02,  4.7952e-04, -1.6490e-02, -1.2393e-01,\n",
      "          2.7755e-03, -3.8390e-02,  5.3667e-02, -1.5538e-02,  8.9568e-02,\n",
      "         -3.7276e-02,  1.6363e-01,  2.3057e-01, -2.5771e-01,  1.9011e-01,\n",
      "         -1.6601e-01, -9.3258e-02,  2.4872e-01,  1.4147e-01,  1.8205e-01],\n",
      "        [ 2.2669e-02, -7.0290e-02, -4.2697e-02, -1.9941e-02, -2.0103e-01,\n",
      "         -1.0343e-01, -5.1022e-02, -8.0101e-02, -1.3085e-02,  1.4541e-01,\n",
      "         -2.0155e-02,  1.4975e-01,  1.3829e-01, -3.6876e-02,  1.2948e-03,\n",
      "         -3.0771e-02, -4.9497e-03,  1.8668e-02, -5.2436e-03,  8.0343e-02],\n",
      "        [ 4.2881e-02,  1.4437e-03,  7.0139e-02,  1.7104e-01, -4.4010e-01,\n",
      "         -6.9566e-02,  9.2209e-03, -5.4631e-02,  2.3243e-03,  1.7583e-01,\n",
      "         -3.0765e-03,  3.3935e-01,  2.8794e-01, -6.2619e-02,  4.3229e-02,\n",
      "         -1.2192e-01,  4.8755e-02,  9.2037e-02,  2.7221e-01,  2.9544e-01],\n",
      "        [ 7.3668e-02,  4.1084e-02,  1.0898e-02, -4.8681e-02, -2.5591e-01,\n",
      "         -9.2086e-02, -1.9281e-02, -9.6753e-03,  1.7328e-02,  1.9365e-02,\n",
      "         -6.0035e-02,  1.0654e-01,  2.0343e-01, -1.8935e-01,  4.4183e-02,\n",
      "         -2.4566e-02, -2.1630e-02, -3.8674e-02,  1.0851e-01,  1.1767e-01],\n",
      "        [ 1.3991e-02, -4.3815e-02, -1.0857e-02, -1.4691e-01, -2.1337e-01,\n",
      "         -2.2697e-01,  7.7497e-03, -4.7359e-02,  5.6323e-02,  1.2764e-01,\n",
      "         -1.2366e-02,  9.7832e-02,  1.5894e-01, -4.8477e-02,  8.0757e-02,\n",
      "          9.8704e-02,  8.8443e-02, -3.1098e-02, -7.9787e-02,  1.0599e-01],\n",
      "        [ 2.6768e-02, -1.1340e-01, -2.6274e-02,  8.2136e-02, -3.8205e-01,\n",
      "         -5.8105e-03, -9.0474e-02, -9.4499e-02, -6.5401e-03,  2.4898e-02,\n",
      "         -3.4750e-02,  1.7591e-01,  2.8741e-01, -2.8772e-02,  1.2830e-01,\n",
      "         -2.9913e-02,  1.0855e-01,  3.3143e-02,  1.5751e-01,  1.1574e-01],\n",
      "        [ 3.3280e-02, -1.1288e-01, -2.0807e-02,  8.5860e-02, -2.5254e-01,\n",
      "         -9.1522e-02,  8.5432e-02,  1.9701e-02, -8.1885e-02,  1.8426e-02,\n",
      "         -4.7909e-02,  2.8369e-01,  8.9927e-02, -9.7560e-02, -1.3438e-02,\n",
      "         -2.1196e-02, -1.1326e-02,  4.5304e-02,  1.3738e-01,  1.5683e-01],\n",
      "        [-7.1547e-02, -5.8901e-02,  6.5149e-03,  1.0021e-01, -2.0258e-01,\n",
      "         -2.2976e-01,  3.9700e-02,  3.5843e-02,  1.4833e-01,  1.7089e-01,\n",
      "         -4.4804e-02,  4.9926e-02,  6.8508e-02, -1.0645e-01, -1.3987e-02,\n",
      "         -8.1313e-02, -4.0037e-02, -9.3396e-03,  3.8967e-02,  2.1761e-01],\n",
      "        [ 7.2019e-02,  1.7156e-03,  8.0387e-02,  1.9909e-01, -4.1141e-01,\n",
      "         -1.8134e-01, -1.2331e-01, -8.4454e-02,  4.1880e-02,  2.6507e-01,\n",
      "         -3.0620e-02,  3.2301e-01,  2.5942e-01, -1.1616e-01,  5.0927e-02,\n",
      "         -2.2854e-02, -3.9488e-02,  6.9217e-02,  2.4800e-01,  2.4011e-01],\n",
      "        [-1.5150e-02, -8.7872e-03, -3.9832e-02, -6.2438e-02, -1.5522e-01,\n",
      "         -9.7393e-02,  6.4694e-02, -9.5530e-02,  2.3454e-02,  1.5295e-01,\n",
      "         -3.4755e-02,  1.1156e-01,  1.8935e-01, -8.1052e-02,  5.8548e-02,\n",
      "         -5.3240e-02, -3.7101e-02, -2.5473e-02, -1.1613e-02,  8.2033e-02],\n",
      "        [ 7.2994e-02, -3.6995e-02, -1.2392e-01, -5.9848e-02, -2.2852e-01,\n",
      "         -4.5142e-02,  2.5650e-02, -5.0870e-02, -2.1927e-02,  5.4498e-02,\n",
      "         -1.9961e-02,  1.1646e-01,  2.2253e-01, -8.5559e-02,  7.2520e-02,\n",
      "         -5.0765e-02, -5.7563e-02,  1.8415e-02,  1.2621e-01,  3.5348e-02],\n",
      "        [ 3.7679e-02, -1.4256e-01, -2.9829e-02, -5.4036e-03, -2.5510e-01,\n",
      "         -1.2580e-01, -1.0757e-02, -8.1239e-02,  6.8903e-02,  6.0423e-02,\n",
      "         -4.6120e-02,  1.8065e-01,  1.9982e-01, -7.0957e-02,  7.1862e-02,\n",
      "         -1.2803e-02,  1.2502e-01, -4.1893e-02,  6.1307e-02,  1.7373e-02],\n",
      "        [ 1.2757e-01, -5.4724e-02,  7.1445e-02,  1.3029e-01, -3.7317e-01,\n",
      "          6.1277e-03,  2.3030e-02, -6.9320e-02, -6.0736e-02,  8.2007e-02,\n",
      "         -2.3015e-03,  2.1095e-01,  1.4122e-01, -8.8508e-02,  7.2024e-02,\n",
      "         -4.4407e-02,  3.2580e-02, -2.0088e-02,  2.1474e-01,  2.3522e-01],\n",
      "        [ 1.0310e-01, -1.8011e-02,  3.9980e-02, -4.0566e-03, -2.2495e-01,\n",
      "         -1.0849e-01, -3.8995e-02,  4.4133e-02, -4.8553e-02,  1.0846e-01,\n",
      "         -3.9265e-02,  6.6890e-02,  2.5074e-01, -1.1997e-01,  7.1645e-02,\n",
      "         -2.4196e-02, -6.7611e-02, -7.0862e-02, -1.4688e-02,  1.0612e-01]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([ 5, 10,  4,  6,  9, 15, 15,  1, 14,  7, 11, 12,  6, 18, 12, 16, 13,  9,\n",
      "         5, 15,  8, 18,  4, 17,  4,  6,  2, 10, 11,  4,  3, 17])\n",
      "tensor([[ 8.3410e-03, -5.0500e-02,  8.5852e-03,  2.2082e-03, -1.2023e-01,\n",
      "         -9.5092e-02,  6.7599e-02,  4.9926e-03, -5.6780e-02,  1.5036e-01,\n",
      "          2.6968e-02,  1.1545e-01,  2.4380e-01, -1.8637e-01,  1.7095e-01,\n",
      "         -6.6549e-02, -2.9433e-02, -2.4594e-02,  1.3661e-01,  1.2577e-01],\n",
      "        [ 6.5344e-02, -5.4864e-02, -1.6253e-02,  5.3269e-02, -2.0636e-01,\n",
      "         -6.9278e-02, -5.8819e-02, -2.0525e-02, -5.2302e-02,  1.1380e-01,\n",
      "         -1.0429e-01,  1.6461e-01,  2.1749e-01, -1.3767e-01,  9.6184e-02,\n",
      "         -9.2868e-03,  7.3038e-02, -6.0297e-02,  9.3582e-02,  7.4194e-02],\n",
      "        [ 3.8014e-02, -6.6757e-02,  3.6088e-02,  5.1103e-02, -2.7712e-01,\n",
      "         -5.6429e-02,  5.9814e-03, -2.8911e-02,  1.1988e-02,  2.0119e-01,\n",
      "         -4.9764e-02,  1.5642e-01,  2.4972e-01, -7.0293e-02,  9.0216e-02,\n",
      "          2.8041e-02,  2.0257e-02,  1.4172e-02,  1.4268e-01,  1.7935e-01],\n",
      "        [ 7.2547e-02, -9.8329e-02, -4.1080e-02,  1.4313e-01, -2.9170e-01,\n",
      "         -9.7266e-02, -3.4581e-02, -4.3674e-02,  3.5563e-02,  2.0032e-01,\n",
      "          4.6593e-02,  1.4228e-01,  1.4375e-01, -7.9841e-02,  1.0836e-01,\n",
      "         -2.1529e-02, -3.5391e-02, -1.0047e-01,  1.2420e-01,  1.7696e-01],\n",
      "        [ 2.3235e-02, -1.1081e-01,  5.7176e-03, -1.5247e-02, -2.2766e-01,\n",
      "         -9.3093e-02, -4.5725e-02, -1.1659e-01, -3.6745e-03,  1.8824e-01,\n",
      "         -2.8628e-02,  1.8482e-01,  1.8484e-01, -3.3164e-02,  9.3571e-02,\n",
      "         -2.7375e-02,  8.5150e-03, -9.4567e-03,  9.1705e-02,  1.5001e-01],\n",
      "        [-2.1569e-02, -2.7754e-02,  2.8720e-02,  1.2865e-02, -2.4334e-01,\n",
      "         -1.4695e-01,  1.2583e-02, -1.8261e-02, -9.5581e-02,  1.0364e-01,\n",
      "         -2.4631e-01,  1.0104e-01,  1.5021e-01, -8.4631e-02,  6.9877e-02,\n",
      "         -1.1661e-01,  4.0513e-02,  4.6401e-03,  2.3129e-01,  1.2109e-01],\n",
      "        [ 3.5455e-02, -1.5799e-01, -1.0067e-01, -4.9971e-02, -2.2050e-01,\n",
      "         -6.1180e-02, -7.1136e-02, -9.2047e-02,  4.3863e-02,  2.2307e-01,\n",
      "         -8.2584e-03,  1.6007e-01,  2.4067e-01, -2.3439e-02,  1.6763e-01,\n",
      "          6.5989e-02, -2.3121e-02, -5.0092e-02,  6.0667e-02,  9.9804e-02],\n",
      "        [-4.0824e-03, -9.6931e-02,  6.3683e-02,  1.0463e-01, -2.8761e-01,\n",
      "         -1.1816e-01, -6.5629e-02,  7.7865e-04, -7.0681e-02,  2.1756e-01,\n",
      "         -2.1648e-02,  1.0816e-01,  1.3510e-01, -9.7074e-02,  1.8622e-01,\n",
      "         -6.6695e-02,  3.7966e-02,  8.5234e-02,  1.8839e-01,  2.2944e-01],\n",
      "        [-1.3575e-02, -5.5413e-02,  5.6306e-02,  3.4653e-02, -2.1821e-01,\n",
      "         -1.0492e-01,  7.6460e-02, -2.1538e-02,  1.0096e-01,  6.7573e-02,\n",
      "         -3.9552e-02,  2.1216e-01,  1.2833e-01, -4.1164e-02, -8.3716e-02,\n",
      "         -2.2054e-01, -1.2442e-02,  2.3685e-02,  4.0052e-02,  1.5742e-01],\n",
      "        [-1.2981e-02, -3.8190e-02, -1.2675e-01, -3.4928e-03, -9.8893e-02,\n",
      "         -2.2321e-02,  8.4952e-02, -8.3010e-02, -8.3377e-02,  1.2862e-01,\n",
      "          3.1927e-02,  1.2662e-01,  1.8715e-01, -1.3637e-01,  1.0866e-01,\n",
      "         -1.8557e-02, -8.4041e-03, -1.2006e-01,  1.2673e-01,  7.5451e-02],\n",
      "        [ 7.1965e-03, -2.9824e-02, -2.3340e-02, -6.7563e-02, -2.0341e-01,\n",
      "         -9.2294e-02, -3.6748e-02,  1.5481e-02,  3.5122e-03,  1.7001e-01,\n",
      "         -3.5457e-02,  1.1946e-01,  2.0872e-01, -1.8075e-02,  4.9663e-02,\n",
      "         -5.3757e-02,  3.8301e-03, -9.9822e-02,  5.1758e-02,  4.3308e-02],\n",
      "        [-6.4852e-02, -3.6799e-02, -1.1064e-02,  4.6254e-02, -2.0270e-01,\n",
      "         -8.1658e-02, -5.8764e-03, -7.7843e-03, -1.6925e-02,  1.3858e-01,\n",
      "         -4.6154e-02,  1.5928e-01,  1.2972e-01, -1.1689e-01,  1.8325e-01,\n",
      "          6.9933e-02,  4.2752e-02, -6.1514e-02,  8.8142e-02,  8.8399e-02],\n",
      "        [ 5.0854e-02,  5.9914e-02,  7.5532e-02,  1.3871e-01, -4.7079e-01,\n",
      "         -8.9258e-02, -7.0345e-02, -4.9880e-02, -3.1631e-02,  1.8031e-01,\n",
      "         -3.0547e-02,  2.3748e-01,  2.2695e-01, -9.2191e-02,  1.4304e-01,\n",
      "         -8.9113e-02, -1.0905e-01,  7.4211e-02,  2.7384e-01,  3.5715e-01],\n",
      "        [ 3.1618e-02, -9.6432e-02, -1.1517e-01,  3.3076e-02, -1.7092e-01,\n",
      "         -6.9733e-02,  1.6113e-02, -1.7361e-02, -2.2848e-02,  1.2882e-01,\n",
      "         -8.2508e-02,  1.3715e-01,  3.1469e-01, -4.8454e-02, -2.5757e-04,\n",
      "         -5.8758e-02,  8.0834e-02, -3.1421e-02,  9.1856e-02,  1.2211e-02],\n",
      "        [ 1.1414e-01, -2.7294e-02, -1.9282e-02,  1.9730e-02, -3.4658e-01,\n",
      "         -1.6051e-01, -3.2366e-02, -1.1381e-01,  5.5860e-02,  1.2812e-01,\n",
      "          9.4534e-02,  1.4180e-01,  2.2815e-01, -1.2047e-01,  1.8071e-01,\n",
      "          4.0494e-02, -2.3527e-02, -4.4414e-03,  1.6132e-01,  2.3025e-01],\n",
      "        [ 1.4247e-02, -1.0631e-01, -2.1614e-02,  2.8024e-02, -2.3685e-01,\n",
      "         -8.3333e-02,  1.1833e-02, -2.1070e-02, -5.3911e-03,  9.0561e-02,\n",
      "         -2.0298e-01,  1.4076e-01,  2.1523e-01, -4.9641e-02,  5.6581e-02,\n",
      "         -7.0696e-02,  1.2213e-02, -3.4737e-02,  4.6330e-02,  2.0442e-01],\n",
      "        [ 5.8891e-02, -3.2779e-03, -1.3426e-01,  9.7952e-02, -3.7575e-01,\n",
      "         -1.0959e-01, -5.4377e-02, -1.1703e-01,  4.5836e-02,  1.3172e-01,\n",
      "         -6.7425e-02,  1.7123e-01,  2.1908e-01, -6.1561e-02,  1.1636e-01,\n",
      "          1.2712e-02, -7.1705e-02, -5.8904e-02,  1.6736e-01,  2.6343e-01],\n",
      "        [ 3.9405e-02, -8.4929e-02, -5.4312e-02, -1.0557e-01, -1.9386e-01,\n",
      "         -4.0331e-02,  2.7407e-02, -4.8138e-02, -4.7796e-03,  7.1599e-02,\n",
      "         -8.0131e-02,  1.1637e-01,  1.8968e-01, -1.5902e-01,  1.0701e-01,\n",
      "          2.5319e-02,  4.6468e-02, -1.2644e-01, -1.0408e-02,  2.4005e-01],\n",
      "        [ 7.8852e-02, -1.0176e-01, -1.5168e-01,  5.8160e-02, -2.1329e-01,\n",
      "         -4.5737e-02,  4.0585e-02, -1.0297e-01,  7.8839e-02,  1.6268e-01,\n",
      "         -3.0685e-02,  1.3377e-01,  2.0918e-01, -7.9711e-02,  1.1625e-01,\n",
      "         -4.1791e-02, -6.6210e-03, -2.6877e-03,  2.0333e-01,  1.5273e-01],\n",
      "        [ 6.9594e-02, -3.2988e-02, -1.5985e-02,  3.7850e-02, -2.5869e-01,\n",
      "         -5.9381e-02, -3.3888e-02, -1.2445e-01,  3.3006e-03,  1.4704e-01,\n",
      "         -1.6905e-03,  1.0350e-01,  1.8639e-01, -1.7646e-01,  8.2568e-02,\n",
      "         -1.9371e-02, -3.2419e-02, -6.5226e-03,  1.5723e-01,  1.6169e-01],\n",
      "        [ 3.1578e-02, -4.0456e-02, -9.6852e-02, -8.0323e-02, -2.1728e-01,\n",
      "         -2.0290e-01,  1.6898e-02, -2.3276e-02,  1.0306e-01,  9.3990e-02,\n",
      "         -4.5530e-02,  1.9634e-01,  1.5739e-01, -6.4944e-02,  2.4261e-03,\n",
      "         -6.3917e-02,  5.0938e-03, -3.7905e-02,  2.5962e-02,  1.0768e-01],\n",
      "        [ 8.2137e-02, -3.1003e-02, -4.1048e-02,  1.3607e-01, -4.4570e-01,\n",
      "         -7.3387e-02,  4.6184e-02, -2.7703e-02,  6.7350e-03,  1.3505e-01,\n",
      "         -3.8145e-02,  1.7518e-01,  2.3312e-01, -1.4706e-01,  6.8794e-02,\n",
      "         -7.1363e-02, -4.3405e-04,  7.0333e-03,  2.3078e-01,  3.4881e-01],\n",
      "        [ 1.1113e-01, -5.7988e-02, -1.5994e-01,  1.3659e-02, -2.0361e-01,\n",
      "         -5.2093e-02,  5.0837e-02, -5.3511e-02, -3.0387e-02,  7.1661e-02,\n",
      "         -1.3727e-02,  1.5010e-01,  2.6207e-01, -1.3022e-01,  1.1049e-01,\n",
      "          4.7680e-03, -1.3235e-02, -2.5279e-02,  8.1254e-02,  1.8824e-01],\n",
      "        [ 4.8623e-02, -7.9852e-02, -6.2380e-02,  1.3953e-04, -2.5796e-01,\n",
      "         -9.0173e-02,  1.3721e-02, -9.9543e-02,  5.7719e-02,  1.4004e-01,\n",
      "         -2.9452e-02,  1.3182e-01,  2.0406e-01, -1.1248e-01,  8.2840e-02,\n",
      "          1.6373e-02,  2.0897e-02, -9.0542e-03,  1.7766e-01,  1.3914e-01],\n",
      "        [ 5.1430e-02, -7.4983e-02, -1.3953e-01, -6.8949e-02, -2.3546e-01,\n",
      "         -9.1321e-02,  9.6201e-03, -5.2363e-02,  1.3602e-02,  9.9399e-02,\n",
      "         -7.0233e-02,  1.1767e-01,  3.0343e-01, -6.2163e-02,  4.6498e-02,\n",
      "          2.6611e-02,  3.9208e-02, -6.5720e-02,  2.5127e-02,  8.2116e-02],\n",
      "        [ 2.3865e-02, -6.3057e-02, -8.3721e-02, -1.2008e-02, -2.6828e-01,\n",
      "         -5.9852e-02, -1.8956e-03, -4.5433e-02, -4.2522e-02,  8.9206e-02,\n",
      "         -9.2918e-02,  1.5371e-01,  1.2744e-01, -5.0049e-02,  9.3171e-02,\n",
      "          1.1590e-02,  4.9130e-02,  1.9905e-02,  1.2239e-01,  1.9126e-01],\n",
      "        [ 8.9242e-02, -1.4641e-01, -2.0777e-02, -1.3236e-02, -2.5378e-01,\n",
      "         -1.8340e-01, -2.2404e-02,  2.4803e-02,  4.3156e-02,  1.2584e-01,\n",
      "          6.0942e-03,  2.3049e-01,  2.2181e-01, -2.4210e-02,  1.4806e-01,\n",
      "          1.8140e-02,  3.1676e-02,  2.7468e-02,  9.5540e-03,  1.6518e-01],\n",
      "        [ 6.2036e-02, -1.3618e-01,  2.5169e-03,  5.2695e-02, -3.6847e-01,\n",
      "         -7.4741e-02, -1.4753e-02, -5.8955e-02,  6.6151e-02,  7.0202e-02,\n",
      "         -1.4377e-01,  1.4760e-01,  2.4659e-01, -1.8390e-02,  7.6882e-02,\n",
      "          1.6096e-02,  5.7249e-02,  1.7881e-02,  1.6149e-01,  1.8902e-01],\n",
      "        [ 5.0875e-02, -6.0355e-02, -1.3064e-01, -8.1539e-02, -2.3209e-01,\n",
      "         -6.2936e-02, -4.7738e-02, -1.1497e-01,  6.5092e-03,  6.7478e-02,\n",
      "          2.9573e-02,  5.0441e-02,  2.2331e-01, -1.0507e-01,  1.4927e-01,\n",
      "          8.1995e-02,  5.3169e-02, -1.0723e-01,  7.5137e-02,  1.8294e-01],\n",
      "        [-2.6832e-02, -4.3518e-02,  4.3806e-03,  6.3116e-02, -2.6153e-01,\n",
      "         -8.4459e-02, -3.1963e-02, -1.0223e-01,  6.9549e-03,  1.8197e-01,\n",
      "         -2.0261e-02,  1.9085e-01,  2.6143e-01, -9.8994e-02,  1.3183e-01,\n",
      "         -4.5399e-02,  2.9598e-02,  1.3146e-02,  1.9485e-01,  2.1009e-01],\n",
      "        [ 1.4549e-01, -5.5666e-02,  2.7321e-02,  1.7848e-01, -4.4911e-01,\n",
      "         -9.3194e-02, -3.9925e-02, -4.6923e-02,  7.1205e-02,  1.7875e-01,\n",
      "         -5.1428e-02,  2.4698e-01,  1.9844e-01, -1.5396e-01,  9.3310e-02,\n",
      "          2.9708e-02,  5.5141e-02,  1.0634e-02,  2.3743e-01,  2.4044e-01],\n",
      "        [-1.0153e-02, -1.0392e-01,  1.3767e-01,  9.3757e-02, -3.4160e-01,\n",
      "         -3.0637e-02, -4.2309e-02, -6.0681e-02, -3.4252e-02,  1.3616e-01,\n",
      "          1.0684e-02,  1.8195e-01,  2.6863e-01, -1.4207e-01,  1.5175e-01,\n",
      "         -2.5001e-02,  4.4388e-02, -2.8903e-02,  1.8155e-02,  1.1807e-01]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([16,  0,  3, 15, 15,  1,  8,  9,  7,  8, 15,  7, 14, 13, 10,  9, 14, 10,\n",
      "        14, 11, 10,  2, 11, 19,  8,  2,  0,  1,  9,  2,  6, 15])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10 # number epoch to train\n",
    "\n",
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_batch, length_batch)\n",
    "        loss = criterion(outputs, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_loader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training for 10 epochs\n",
      "Train Acc 99.91\n",
      "Val Acc 89.3455098934551\n",
      "Test Acc 79.42113648433352\n"
     ]
    }
   ],
   "source": [
    "print (\"After training for {} epochs\".format(num_epochs))\n",
    "print (\"Train Acc {}\".format(test_model(train_loader, model)))\n",
    "print (\"Val Acc {}\".format(test_model(val_loader, model)))\n",
    "print (\"Test Acc {}\".format(test_model(test_loader, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Suppose modify the collate function to the following:\n",
    "```python\n",
    "def newsgroup_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.random.shuffle(np.array(datum[0])),  ##note the addition of shuffle here\n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list), torch.LongTensor(label_list)] ```\n",
    "    \n",
    "a) What would your test and val accuracies be for the model you trained above? Do this and verify that what you think is correct. <br>\n",
    "b) You train your model with this changed collate function. Do you expect to achieve similar results to what you have currently? <br> <br>\n",
    "\n",
    "2 Create and visualize confusion matrix for this. Do you see anything interesting? ( Look at the frequency of occurence of different labels in your train set and see the classification performance on labels that are less frequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Exercises\n",
    "\n",
    "1. Try training the model with larger embedding size and for larger number of epochs. Also plot the training curves of the model\n",
    "2. Try downloading IMDB Large Movie Review Dataset http://ai.stanford.edu/~amaas/data/sentiment/ and tokenize it. After tokenizing the dataset try training Bag-of-Words model on it and report your initial results on validation set. It's again interesting to note the effect of embedding size, tokenization scheme etc on your performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits\n",
    "\n",
    "This lab is built on top of the lab developed for DS-GA 1011 Fall 2018."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
