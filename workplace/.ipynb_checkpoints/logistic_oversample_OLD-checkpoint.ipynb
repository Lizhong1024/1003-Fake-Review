{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from itertools import chain\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('../data/train.csv', index_col='ex_id')\n",
    "val = pd.read_csv('../data/dev.csv', index_col='ex_id')\n",
    "test = pd.read_csv('../data/test_no_label.csv', index_col='ex_id')\n",
    "\n",
    "# Load tokenized data\n",
    "train_data_tokens = pkl.load(open(\"../data/tokens/train_data_tokens.pkl\", \"rb\"))\n",
    "val_data_tokens = pkl.load(open(\"../data/tokens/val_data_tokens.pkl\", \"rb\"))\n",
    "test_data_tokens = pkl.load(open(\"../data/tokens/test_data_tokens.pkl\", \"rb\"))\n",
    "\n",
    "all_train_tokens = list(chain.from_iterable(train_data_tokens))\n",
    "\n",
    "# Get labels\n",
    "y_train = train.label.values\n",
    "y_val = val.label.values\n",
    "y_test = test.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab\n",
    "def build_vocab(all_tokens, threshold):\n",
    "\n",
    "    c = Counter(all_tokens)\n",
    "    vocab = [word for count, word in enumerate(Counter(all_train_tokens)) if count >= 10]\n",
    "    \n",
    "    id2token = vocab\n",
    "    token2id = dict(zip(vocab, range(len(vocab))))\n",
    "    return token2id, id2token\n",
    "\n",
    "token2id, id2token = build_vocab(all_train_tokens, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "count_vec = CountVectorizer(lowercase=False, preprocessor=dummy, tokenizer=dummy, vocabulary=token2id)\n",
    "\n",
    "X_train_count = count_vec.fit_transform(train_data_tokens)\n",
    "X_val_count = count_vec.transform(val_data_tokens)\n",
    "X_test_count = count_vec.transform(test_data_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(lowercase=False, preprocessor=dummy, tokenizer=dummy, vocabulary=token2id)  \n",
    "\n",
    "X_train_tfidf = tfidf_vec.fit_transform(train_data_tokens)\n",
    "X_val_tfidf = tfidf_vec.transform(val_data_tokens)\n",
    "X_test_tfidf = tfidf_vec.transform(test_data_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def evaluate(model, X=X_val_count, y=y_val):\n",
    "    y_scores = model.predict_proba(X)[:, 1]\n",
    "    print('Accuracy: ', model.score(X, y))\n",
    "    print('AUC: ', roc_auc_score(y, y_scores))\n",
    "    print('AP: ', average_precision_score(y, y_scores))\n",
    "    print('\\nConfusion Matrix')\n",
    "    print(confusion_matrix(y, model.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_0 = LogisticRegression(penalty='l2', C=0.1, class_weight=None, max_iter=1000)\n",
    "lr_0.fit(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8972938359596859\n",
      "AUC:  0.7153645451073453\n",
      "AP:  0.20165813686684972\n",
      "\n",
      "Confusion Matrix\n",
      "[[32193    77]\n",
      " [ 3612    36]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(lr_0, X_val_count, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_ros = LogisticRegression(penalty='l2', C=0.1, class_weight=None, max_iter=1000)\n",
    "lr_ros.fit(X_train_ros, y_train_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6541010078512166\n",
      "AUC:  0.7042944349077683\n",
      "AP:  0.1910089446621789\n",
      "\n",
      "Confusion Matrix\n",
      "[[21123 11147]\n",
      " [ 1277  2371]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(lr_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250874, 114041)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450110, 114041)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ros.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversample after rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_count_scaled = preprocessing.scale(X_train_count, axis=0, with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = preprocessing.MaxAbsScaler(copy=True)\n",
    "X_train_count_scaled = transformer.fit_transform(X_train_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE (scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_train_smote_scaled, y_train_smote_scaled = SMOTE().fit_resample(X_train_count_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_smote_scaled = LogisticRegression(penalty='l2', C=0.1, class_weight=None, max_iter=1000)\n",
    "lr_smote_scaled.fit(X_train_smote_scaled, y_train_smote_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6605044824322067\n",
      "AUC:  0.703046602746019\n",
      "AP:  0.19775028449376478\n",
      "\n",
      "Confusion Matrix\n",
      "[[21420 10850]\n",
      " [ 1344  2304]]\n"
     ]
    }
   ],
   "source": [
    "# MaxAbsScaler\n",
    "X_val_count_scaled = transformer.transform(X_val_count)\n",
    "evaluate(lr_smote_scaled, X=X_val_count_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.30728325630603043\n",
      "AUC:  0.6956765558146996\n",
      "AP:  0.19001864481295583\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 7619 24651]\n",
      " [  230  3418]]\n"
     ]
    }
   ],
   "source": [
    "# Standard scaler withoutmean\n",
    "evaluate(lr_smote_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450110, 114041)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_smote_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD (without rescale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_train_smote, y_train_smote = SMOTE().fit_resample(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_smote = LogisticRegression(penalty='l2', C=0.1, class_weight=None, max_iter=1000)\n",
    "lr_smote.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7778272732334762\n",
      "AUC:  0.679911011598954\n",
      "AP:  0.18556007964545324\n",
      "\n",
      "Confusion Matrix\n",
      "[[26573  5697]\n",
      " [ 2283  1365]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(lr_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE (array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_train_smote_2, y_train_smote_2 = SMOTE().fit_resample(X_train_count.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_smote_2 = LogisticRegression(penalty='l2', C=0.1, class_weight=None, max_iter=1000)\n",
    "lr_smote_2.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(lr_smote_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ADASYN, y_train_ADASYN = ADASYN().fit_resample(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_ADASY = LogisticRegression(penalty='l2', C=0.1, class_weight=None, max_iter=1000)\n",
    "lr_ADASY.fit(X_train_ADASYN, y_train_ADASYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.776240325185144\n",
      "AUC:  0.6784568185648503\n",
      "AP:  0.18410894162718627\n",
      "\n",
      "Confusion Matrix\n",
      "[[26526  5744]\n",
      " [ 2293  1355]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(lr_ADASY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTENC (失败)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_nc = SMOTENC(categorical_features=np.ones(X_train_count.shape[1], dtype='bool'))\n",
    "X_train_smote_nc, y_train_smote_nc = smote_nc.fit_resample(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(X_train_count.shape[1], dtype='bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250874, 114041)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
